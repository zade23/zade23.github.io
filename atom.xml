<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ANdRoid&#39;s BLOG</title>
  
  <subtitle>MaTRix</subtitle>
  <link href="https://zade23.github.io/atom.xml" rel="self"/>
  
  <link href="https://zade23.github.io/"/>
  <updated>2025-07-02T07:04:39.731Z</updated>
  <id>https://zade23.github.io/</id>
  
  <author>
    <name>Android</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【图形学】Blender法线贴图渲染并在Unity引擎中查看</title>
    <link href="https://zade23.github.io/2025/07/02/%E3%80%90%E5%9B%BE%E5%BD%A2%E5%AD%A6%E3%80%91Blender%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%E6%B8%B2%E6%9F%93%E5%B9%B6%E5%9C%A8Unity%E5%BC%95%E6%93%8E%E4%B8%AD%E6%9F%A5%E7%9C%8B/"/>
    <id>https://zade23.github.io/2025/07/02/%E3%80%90%E5%9B%BE%E5%BD%A2%E5%AD%A6%E3%80%91Blender%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%E6%B8%B2%E6%9F%93%E5%B9%B6%E5%9C%A8Unity%E5%BC%95%E6%93%8E%E4%B8%AD%E6%9F%A5%E7%9C%8B/</id>
    <published>2025-07-02T07:02:50.000Z</published>
    <updated>2025-07-02T07:04:39.731Z</updated>
    
    <content type="html"><![CDATA[<h1 id="【图形学】Blender渲染法线贴图"><a href="#【图形学】Blender渲染法线贴图" class="headerlink" title="【图形学】Blender渲染法线贴图"></a>【图形学】Blender渲染法线贴图</h1><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021456144.png" alt="1"></p><h2 id="完整流程"><a href="#完整流程" class="headerlink" title="完整流程"></a>完整流程</h2><ol><li><p>打开Blender，不要删除相机📷，导入模型。</p></li><li><p>选择相机角度用来确定最终输出的视图。从右上角视图上可以直接切换（俯视图，正视图等）。</p></li><li><p>确定视图后。点击 Layout → view → Align View → Align Activate Camera to View</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021457121.png" alt="2"></p></li><li><p>相机参数设置。选中相机 → 相机设置为“正交模式” → 正交比例设置为2.000</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021458493.png" alt="3"></p></li><li><p>设置输出分辨率。X和Y分别选择你需要输出的分辨率，一般情况下和贴图尺寸对齐即可。</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021459825.png" alt="4"></p></li><li><p>渲染引擎render选择。渲染引擎切换为“工作台”模式；“颜色管理→查看变换改为“标准”；“光照” → “快照材质” → 选择法线</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021459852.png" alt="5"></p></li><li><p>查看渲染效果。点击“Render” → “Render Image”，也可以使用快捷键F12</p></li><li><p>保存导出。“Image → “Save“，或使用快捷键 Alt+S</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202507021500874.png" alt="6"></p></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.bilibili.com/video/BV1Bg4y1B7J2/?vd_source=31e773b345b9901b4c2886ef721c500e">https://www.bilibili.com/video/BV1Bg4y1B7J2/?vd_source=31e773b345b9901b4c2886ef721c500e</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;【图形学】Blender渲染法线贴图&quot;&gt;&lt;a href=&quot;#【图形学】Blender渲染法线贴图&quot; class=&quot;headerlink&quot; title=&quot;【图形学】Blender渲染法线贴图&quot;&gt;&lt;/a&gt;【图形学】Blender渲染法线贴图&lt;/h1&gt;&lt;h2 id=&quot;流</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【Git】服务器创建SSH私钥拉取Gitlab代码</title>
    <link href="https://zade23.github.io/2025/05/21/%E3%80%90Git%E3%80%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BASSH%E7%A7%81%E9%92%A5%E6%8B%89%E5%8F%96Gitlab%E4%BB%A3%E7%A0%81/"/>
    <id>https://zade23.github.io/2025/05/21/%E3%80%90Git%E3%80%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BASSH%E7%A7%81%E9%92%A5%E6%8B%89%E5%8F%96Gitlab%E4%BB%A3%E7%A0%81/</id>
    <published>2025-05-21T06:09:41.000Z</published>
    <updated>2025-05-21T06:59:26.578Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%A7%81%E9%92%A5">服务器创建个人私钥</a></li><li><a href="#%E5%A4%8D%E5%88%B6%E5%85%AC%E9%92%A5">复制公钥</a></li><li><a href="#%E9%AA%8C%E8%AF%81%E8%BF%9E%E6%8E%A5%E6%80%A7">验证连接性</a></li></ul><pre class="mermaid">graph LR    A[创建个人密钥] --> B[生成 SSH 密钥对]    B --> C[复制公钥]     C --> D[登录 GitLab 账户]    D --> E[转到 SSH 密钥设置]    E --> F[添加 SSH 密钥]    F --> G[验证连接]    G --> H[成功登录 GitLab 账户]</pre><h2 id="服务器创建个人私钥"><a href="#服务器创建个人私钥" class="headerlink" title="服务器创建个人私钥"></a>服务器创建个人私钥</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C <span class="string">&quot;你的邮箱@example.com&quot;</span></span><br></pre></td></tr></table></figure><blockquote><p>生成一个 RSA 类型、4096 位长度的 SSH 密钥，并为其添加一个注释，以便于识别。</p></blockquote><p><strong>ssh-keygen</strong>:</p><ul><li>这是一个用于生成、管理和转换 SSH 密钥的工具。SSH（Secure Shell）协议用于安全地访问远程计算机。</li></ul><p><strong>-t rsa</strong>:</p><ul><li>这个选项指定密钥的类型。在这里，<code>rsa</code> 表示生成 RSA 类型的密钥。RSA 是一种常用的公钥加密算法。</li></ul><p><strong>-b 4096</strong>:</p><ul><li>这个选项指定密钥的位数。<code>4096</code> 表示生成一个 4096 位的密钥，这是一个非常安全的长度，通常推荐用于大多数应用。</li></ul><p><strong>-C “你的邮箱@example.com”</strong>:</p><ul><li>这个选项为生成的密钥添加一个注释。注释通常用于标识密钥的用途或作者，通常使用电子邮件地址。这里的 <code>&quot;你的邮箱@example.com&quot;</code> 应替换为你的实际邮箱地址。</li></ul><h2 id="复制公钥"><a href="#复制公钥" class="headerlink" title="复制公钥"></a>复制公钥</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><p>大概长这样：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-rsa <span class="attr">xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</span>== 你的邮箱@example.com</span><br></pre></td></tr></table></figure><p>复制这个密钥</p><p>在GitLab添加密钥</p><p>User Settings -&gt; SSH keys -&gt; Add new key</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202505211144632.jpg" alt="GitLab添加SSH密钥"></p><p>在key下方的框内粘贴上面复制的密钥，(可选)设置密钥过期时间。</p><h2 id="验证连接性"><a href="#验证连接性" class="headerlink" title="验证连接性"></a>验证连接性</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@gitlab.bt</span><br></pre></td></tr></table></figure><p>当屏幕显示：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Welcome to GitLab, @yourname!</span><br></pre></td></tr></table></figure><p>说明服务器和GitLab已建立连接</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%A7%81%E9%92%A5&quot;&gt;服务器创建个人私钥&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E5%A</summary>
      
    
    
    
    <category term="Git Workflow" scheme="https://zade23.github.io/categories/Git-Workflow/"/>
    
    
    <category term="Git" scheme="https://zade23.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>【图形学】learnOpenGL学习笔记</title>
    <link href="https://zade23.github.io/2025/03/21/%E3%80%90%E5%9B%BE%E5%BD%A2%E5%AD%A6%E3%80%91learnOpenGL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://zade23.github.io/2025/03/21/%E3%80%90%E5%9B%BE%E5%BD%A2%E5%AD%A6%E3%80%91learnOpenGL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2025-03-21T10:34:56.000Z</published>
    <updated>2025-03-21T10:34:56.908Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>【C++】MinGW安装</title>
    <link href="https://zade23.github.io/2025/03/21/%E3%80%90C-%E3%80%91MinGW%E5%AE%89%E8%A3%85/"/>
    <id>https://zade23.github.io/2025/03/21/%E3%80%90C-%E3%80%91MinGW%E5%AE%89%E8%A3%85/</id>
    <published>2025-03-21T09:38:53.000Z</published>
    <updated>2025-03-21T10:29:03.565Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#mingw-%E7%AE%80%E4%BB%8B">MinGW 简介</a></li></ul><h2 id="MinGW-简介"><a href="#MinGW-简介" class="headerlink" title="MinGW 简介"></a>MinGW 简介</h2><p>MinGW (Minimalist GNU for Windows) 是一个免费且开源的软件开发环境，旨在为 Windows 平台提供原生（native）的 GNU 工具集。简单来说，它让你能够在 Windows 上编译和运行原本为 Linux&#x2F;Unix 系统设计的 C、C++ 和 Fortran 程序，而无需依赖庞大的运行时环境，如 Cygwin。</p><h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><ul><li><strong>GCC (GNU Compiler Collection):</strong>  核心的编译器套件，包括 C、C++、Objective-C、Fortran、Ada 等语言的编译器。</li><li><strong>GNU Binutils:</strong> 一组二进制工具，包括链接器 (ld)、汇编器 (as)、目标文件处理工具等，用于创建可执行文件和库。</li><li><strong>GNU Make:</strong>  一个构建自动化工具，用于根据 Makefile 文件中的规则自动编译和链接项目。</li><li><strong>Windows API Headers and Libraries:</strong>  提供 Windows API 的头文件和静态库，使得程序可以访问 Windows 的核心功能（如文件操作、窗口管理、网络通信等）。</li></ul><h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><ul><li><strong>轻量级 (Minimalist):</strong>  MinGW 的目标是提供一个精简的开发环境，只包含必要的工具和库。它避免了像 Cygwin 那样提供完整的 POSIX 兼容层，因此安装包更小，运行时开销也更低。</li><li><strong>原生 Windows 应用 (Native):</strong> MinGW 编译出的程序是原生的 Windows 可执行文件 (EXE) 或动态链接库 (DLL)。它们不依赖于任何额外的运行时环境 (除了 Windows 本身)，因此可以轻松地在其他 Windows 机器上运行，无需安装 MinGW。  这是与 Cygwin 的主要区别，Cygwin 程序需要 Cygwin1.dll 才能运行。</li><li><strong>开源免费 (Free and Open Source):</strong> MinGW 是完全免费和开源的，遵循 GPL 和类似的自由软件许可证。</li><li><strong>与 MSVC 兼容性 (Limited):</strong> MinGW 生成的代码通常与 Microsoft Visual C++ (MSVC) 不完全兼容。虽然它们都遵循 C&#x2F;C++ 标准，但由于 ABI (Application Binary Interface) 的差异，由 MinGW 编译的库可能无法直接与 MSVC 编译的代码链接，反之亦然。 然而，MinGW 能够使用 MSVC 提供的 CRT (C Runtime Library)。</li><li><strong>易于使用:</strong> MinGW 相对容易安装和配置。你可以使用命令行工具（如 GCC 和 Make）进行编译，也可以将其集成到各种 IDE（如 Code::Blocks、Eclipse CDT、Dev-C++ 等）中。</li></ul><h2 id="MinGW-和-MinGW-w64-的区别"><a href="#MinGW-和-MinGW-w64-的区别" class="headerlink" title="MinGW 和 MinGW-w64 的区别"></a>MinGW 和 MinGW-w64 的区别</h2><ul><li><strong>MinGW:</strong> 最初的 MinGW 项目主要针对 32 位 Windows 系统。它在 64 位 Windows 上也可以运行，但通常只能编译 32 位程序。</li><li><strong>MinGW-w64:</strong>  是一个独立的项目，从 MinGW 派生而来，但进行了扩展以支持 64 位 Windows 系统。它可以同时编译 32 位和 64 位程序。 <strong>现在，MinGW-w64 是更推荐使用的版本，因为它更活跃、功能更强大、支持更广泛。</strong>  当人们现在提到 “MinGW” 时，通常是指 MinGW-w64。</li></ul><h2 id="MinGW-w64-的主要优势"><a href="#MinGW-w64-的主要优势" class="headerlink" title="MinGW-w64 的主要优势"></a>MinGW-w64 的主要优势</h2><ul><li><strong>支持 64 位 Windows：</strong> 可以编译和运行原生的 64 位 Windows 应用程序。</li><li><strong>更广泛的库支持：</strong> MinGW-w64 社区提供了许多预编译的第三方库，方便开发者使用。</li><li><strong>更活跃的开发：</strong> MinGW-w64 项目比原始的 MinGW 项目更加活跃，Bug 修复和新功能添加更频繁。</li><li><strong>线程模型选择:</strong>  MinGW-w64 提供了两种线程模型: <code>posix</code> 和 <code>win32</code>。  <code>posix</code> 使用 pthreads 库，更接近 Unix&#x2F;Linux 的线程模型，而 <code>win32</code> 使用 Windows 原生的线程 API。 选择哪种模型取决于你的需求和代码的可移植性考虑。</li></ul><h2 id="安装-MinGW-w64-推荐方法-MSYS2"><a href="#安装-MinGW-w64-推荐方法-MSYS2" class="headerlink" title="安装 MinGW-w64 (推荐方法 - MSYS2)"></a>安装 MinGW-w64 (推荐方法 - MSYS2)</h2><p>MSYS2 是一个基于 Cygwin 和 MinGW-w64 的软件发行版和构建平台，提供了一个类似 Linux 的环境，并包含了包管理器 (Pacman)，使得安装和管理 MinGW-w64 工具链及其他软件包变得非常容易。</p><ol><li><p><strong>下载 MSYS2:</strong> 从 MSYS2 官方网站 <a href="https://www.msys2.org/">https://www.msys2.org/</a> 下载安装程序。</p></li><li><p><strong>安装 MSYS2:</strong>  运行安装程序，并按照指示完成安装。</p></li><li><p><strong>更新 MSYS2:</strong> 打开 MSYS2 终端 (通常在开始菜单中找到)，并运行以下命令：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -Syuu</span><br></pre></td></tr></table></figure><p> 如果提示关闭终端并重新打开，请照做，然后再次运行 <code>pacman -Syuu</code>，直到没有更新为止。</p></li><li><p><strong>安装 MinGW-w64 工具链:</strong></p><ul><li><p>对于 64 位工具链：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S mingw-w64-x86_64-toolchain</span><br></pre></td></tr></table></figure></li><li><p>对于 32 位工具链：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S mingw-w64-i686-toolchain</span><br></pre></td></tr></table></figure></li><li><p>你也可以两个都安装。</p></li></ul></li><li><p><strong>添加 MinGW-w64 到 PATH 环境变量：</strong></p><ul><li>编辑系统环境变量 (搜索 “编辑系统环境变量”)。</li><li>在 “系统变量” 下找到 <code>Path</code> 变量，点击 “编辑”。</li><li>点击 “新建”，并添加 MinGW-w64 的 <code>bin</code> 目录路径。<ul><li>对于 64 位，通常是 <code>C:\msys64\mingw64\bin</code> (根据你的 MSYS2 安装路径调整)。</li><li>对于 32 位，通常是 <code>C:\msys64\mingw32\bin</code>。<br> <img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202503211828548.jpg" alt="目录路径"></li></ul></li><li>确定并关闭所有对话框。</li></ul></li><li><p><strong>验证安装:</strong> 打开一个新的命令提示符 (cmd) 或 PowerShell 窗口，输入以下命令：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc --version</span><br><span class="line">g++ --version</span><br></pre></td></tr></table></figure><p> 如果显示 GCC 的版本信息，则表示安装成功。<br> <img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202503211827370.jpg" alt="安装成功"></p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MinGW (特别是 MinGW-w64) 是一个优秀的工具，可以让你在 Windows 上使用 GNU 工具链进行 C&#x2F;C++ 开发，生成原生的 Windows 应用程序。</p><p>推荐使用 MSYS2 来安装和管理 MinGW-w64，因为它提供了便捷的包管理和更新机制。</p><p>如果你需要构建跨平台应用程序，或者需要使用一些只在 Linux&#x2F;Unix 上可用的库，MinGW 是一个很好的选择。 如果你需要与 MSVC 代码完全兼容，则应考虑使用 Microsoft Visual C++。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#mingw-%E7%AE%80%E4%BB%8B&quot;&gt;MinGW 简介&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;MinGW-简介&quot;&gt;&lt;a href=&quot;#MinGW-简介&quot; class=&quot;headerlink&quot; title=&quot;MinGW 简</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【Python】哪些类型的变量应该放在__init__方法(构造函数)中</title>
    <link href="https://zade23.github.io/2025/03/06/%E3%80%90Python%E3%80%91%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8F%98%E9%87%8F%E5%BA%94%E8%AF%A5%E6%94%BE%E5%9C%A8-init-%E6%96%B9%E6%B3%95-%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0-%E4%B8%AD/"/>
    <id>https://zade23.github.io/2025/03/06/%E3%80%90Python%E3%80%91%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8F%98%E9%87%8F%E5%BA%94%E8%AF%A5%E6%94%BE%E5%9C%A8-init-%E6%96%B9%E6%B3%95-%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0-%E4%B8%AD/</id>
    <published>2025-03-06T08:49:49.000Z</published>
    <updated>2025-03-06T08:56:20.638Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#0%E8%B5%B7%E5%9B%A0">0起因</a></li><li><a href="#1%E4%BB%A5%E4%B8%8B%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8F%98%E9%87%8F%E6%94%BE%E5%9C%A8__init__">1以下类型的变量放在<code>__init__</code></a></li><li><a href="#2%E6%80%BB%E7%BB%93">2总结</a></li></ul><h2 id="0起因"><a href="#0起因" class="headerlink" title="0起因"></a>0起因</h2><p>最近，在刷题的过程中思考如何把代码的向量命名规范化，进一步的希望规范化完整的代码功能和设计模式。</p><p>以 leetcode第3题：<a href="https://leetcode.cn/problems/longest-substring-without-repeating-characters/">https://leetcode.cn/problems/longest-substring-without-repeating-characters/</a>为例。</p><p>正常代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        char_index = &#123;&#125;  <span class="comment"># Maps character to its last position</span></span><br><span class="line">        max_length = <span class="number">0</span></span><br><span class="line">        start = <span class="number">0</span>  <span class="comment"># Start of current substring</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="comment"># If character is already in the current substring, update start position</span></span><br><span class="line">            <span class="keyword">if</span> s[i] <span class="keyword">in</span> char_index <span class="keyword">and</span> char_index[s[i]] &gt;= start:</span><br><span class="line">                start = char_index[s[i]] + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># Update max_length if current substring is longer</span></span><br><span class="line">                max_length = <span class="built_in">max</span>(max_length, i - start + <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Update last position of character</span></span><br><span class="line">            char_index[s[i]] = i</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> max_length</span><br></pre></td></tr></table></figure><p>这是通常的LeetCode格式，没有问题。</p><p>但是，如果想定义一个构造函数<code>__init__</code>初始化向量那应该怎么做呢？</p><p>于是，按照逻辑和想法写了一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.lst = &#123;&#125;</span><br><span class="line">        self.longest_substr = <span class="number">0</span></span><br><span class="line">        self.start = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> s[i] <span class="keyword">in</span> self.lst <span class="keyword">and</span> self.lst[s[i]] &gt;= self.start:</span><br><span class="line">                self.start = self.lst[s[i]] + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.longest_substr = <span class="built_in">max</span>(self.longest_substr, i - self.start + <span class="number">1</span>)</span><br><span class="line">            self.lst[s[i]] = i</span><br><span class="line">        <span class="keyword">return</span> self.longest_substr</span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>写完之后，诞生一个新的问题：能不能把 <code>n</code> 这个长度向量也放在初始化中呢？</p><p>答案是不行，更应该说是“不规范”。</p><h2 id="1以下类型的变量放在-init"><a href="#1以下类型的变量放在-init" class="headerlink" title="1以下类型的变量放在__init__"></a>1以下类型的变量放在<code>__init__</code></h2><p><code>__init__</code> 方法（构造函数）用于初始化一个类的<em>实例</em>的状态。</p><p>因此，你应该把以下类型的变量放在 <code>__init__</code> 中：</p><ol><li><p><strong>属于对象本身的属性 (Attributes that belong to the object itself):</strong></p><ul><li><p>这些变量描述了对象的特征或状态，并且在对象的整个生命周期内都可能被使用。</p></li><li><p>它们对于每个对象实例来说可能是不同的。</p></li><li><p>例子：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, breed, age</span>):</span><br><span class="line">        self.name = name  <span class="comment"># 属于狗的名字</span></span><br><span class="line">        self.breed = breed <span class="comment"># 属于狗的品种</span></span><br><span class="line">        self.age = age    <span class="comment"># 属于狗的年龄</span></span><br><span class="line"></span><br><span class="line">my_dog = Dog(<span class="string">&quot;Buddy&quot;</span>, <span class="string">&quot;Golden Retriever&quot;</span>, <span class="number">3</span>)</span><br><span class="line">your_dog = Dog(<span class="string">&quot;Lucy&quot;</span>, <span class="string">&quot;Labrador&quot;</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># my_dog 和 your_dog 有不同的 name, breed, age</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>对象创建时必须提供的参数 (Parameters required when creating the object):</strong></p><ul><li>这些参数是创建对象时不可或缺的，用于设置对象的初始状态。</li><li>它们通常被用来初始化对象的属性。</li><li>例子（和上面一样）：<code>name</code>, <code>breed</code>, <code>age</code> 是创建 <code>Dog</code> 对象时必须提供的。</li></ul></li><li><p><strong>对象内部使用的，但不需要外部直接访问的变量 (Variables used internally by the object, but not directly accessed externally):</strong></p><ul><li><p>这些变量通常用于存储对象的内部状态，或者作为对象方法的辅助变量。</p></li><li><p>它们通常以下划线 <code>_</code> 开头（例如 <code>self._internal_counter</code>），这是一种约定，表示它们是“私有的”或“受保护的”，不建议从对象外部直接访问。</p></li><li><p>例子：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Circle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, radius</span>):</span><br><span class="line">        self.radius = radius</span><br><span class="line">        self._area = <span class="number">3.14159</span> * radius * radius  <span class="comment"># 内部计算的面积，不直接暴露</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_area</span>(<span class="params">self</span>):  <span class="comment"># 提供一个方法来获取面积</span></span><br><span class="line">        <span class="keyword">return</span> self._area</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>与对象关联的其他对象 (Other objects associated with the object):</strong></p><ul><li><p>如果一个对象需要与其他对象协作，那么这些其他对象的引用可以作为属性存储在 <code>__init__</code> 中。  这体现了对象之间的“has-a”关系（组合或聚合）。</p></li><li><p>例子：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Engine</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, horsepower</span>):</span><br><span class="line">        self.horsepower = horsepower</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, make, model, engine</span>):</span><br><span class="line">        self.make = make</span><br><span class="line">        self.model = model</span><br><span class="line">        self.engine = engine  <span class="comment"># Car &quot;has-a&quot; Engine</span></span><br><span class="line"></span><br><span class="line">my_engine = Engine(<span class="number">200</span>)</span><br><span class="line">my_car = Car(<span class="string">&quot;Toyota&quot;</span>, <span class="string">&quot;Camry&quot;</span>, my_engine)</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>默认值属性 (Attributes with default values):</strong></p><ul><li><p>如果某些属性在对象创建时可以不提供，你可以给它们设置默认值。</p></li><li><p>例子：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, width, height=<span class="number">1</span></span>):  <span class="comment"># height 有默认值 1</span></span><br><span class="line">        self.width = width</span><br><span class="line">        self.height = height</span><br><span class="line"></span><br><span class="line">rect1 = Rectangle(<span class="number">5</span>)     <span class="comment"># height 使用默认值 1</span></span><br><span class="line">rect2 = Rectangle(<span class="number">5</span>, <span class="number">10</span>)  <span class="comment"># height 被指定为 10</span></span><br></pre></td></tr></table></figure></li></ul></li></ol><p><strong>不应该放在 <code>__init__</code> 中的变量:</strong></p><ul><li><p><strong>局部变量 (Local variables):</strong> 只在某个方法内部使用的临时变量，不属于对象的状态，应该在方法内部定义。</p></li><li><p><strong>与特定方法调用相关的变量 (Variables related to a specific method call):</strong>  例如，<code>lengthOfLongestSubstring</code> 方法中的 <code>n</code>，它是输入字符串 <code>s</code> 的长度，与对象本身的状态无关，应该在方法内部计算。</p></li><li><p><strong>类级别的变量 (Class-level variables):</strong>  这些变量属于类本身，而不是类的实例。它们应该在类定义中直接定义，而不是在 <code>__init__</code> 中。  类变量在所有实例之间共享。</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span>:</span><br><span class="line">    class_variable = <span class="number">0</span>  <span class="comment"># 类变量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, instance_variable</span>):</span><br><span class="line">        self.instance_variable = instance_variable  <span class="comment"># 实例变量</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="2总结"><a href="#2总结" class="headerlink" title="2总结"></a>2总结</h2><p><code>__init__</code> 的目的是初始化<em>对象</em>的状态。</p><p>变量是否应该放在 <code>__init__</code> 中，取决于它是否是对象持久状态的一部分，或者是否在对象创建时必须提供。</p><p>清晰地区分对象的属性（放在 <code>__init__</code> 中）和方法的局部变量（放在方法内部）对于编写清晰、可维护的代码至关重要。</p><p>在LeetCode第三题中，<code>n</code>与特定的调用方法相关而且与对象本身状态无关，应该在方法内部计算。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#0%E8%B5%B7%E5%9B%A0&quot;&gt;0起因&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1%E4%BB%A5%E4%B8%8B%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8F%98%E9%87%8F%E6%94%BE</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【工具】个人向SSH工具及相关设置</title>
    <link href="https://zade23.github.io/2025/01/16/%E3%80%90%E5%B7%A5%E5%85%B7%E3%80%91%E4%B8%AA%E4%BA%BA%E5%90%91SSH%E5%B7%A5%E5%85%B7%E5%8F%8A%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"/>
    <id>https://zade23.github.io/2025/01/16/%E3%80%90%E5%B7%A5%E5%85%B7%E3%80%91%E4%B8%AA%E4%BA%BA%E5%90%91SSH%E5%B7%A5%E5%85%B7%E5%8F%8A%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/</id>
    <published>2025-01-16T06:56:19.000Z</published>
    <updated>2025-08-27T08:44:15.041Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#ssh%E5%B7%A5%E5%85%B7">SSH工具</a></li><li><a href="#%E9%85%8D%E8%89%B2%E6%96%B9%E6%A1%88">配色方案</a></li><li><a href="#%E5%AD%97%E4%BD%93">字体</a></li><li><a href="#%E6%8C%89%E9%94%AE%E8%AE%BE%E7%BD%AE">按键设置</a></li><li><a href="#filezilla%E9%85%8D%E7%BD%AE">FileZilla配置</a></li><li><a href="#tmux%E9%85%8D%E7%BD%AE">Tmux配置</a><ul><li><a href="#%E9%BC%A0%E6%A0%87%E5%8D%8F%E5%8A%A9">鼠标协助</a></li></ul></li><li><a href="#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C">最终效果</a></li><li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li></ul><h2 id="SSH工具"><a href="#SSH工具" class="headerlink" title="SSH工具"></a>SSH工具</h2><p>SSH终端：Putty</p><p>文件传输工具：FileZilla</p><p>分屏&#x2F;后台工具: Tmux</p><h2 id="配色方案"><a href="#配色方案" class="headerlink" title="配色方案"></a>配色方案</h2><p>可从 <a href="https://putty.org.ru/themes">PuTTY Color Themes</a> 上找</p><p>我个人使用的主题：<a href="https://putty.org.ru/themes/igvita-desert">19. Igvita Desert</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CURRENT_USER\Software\SimonTatham\PuTTY\Sessions\&lt;填写你想要适配的保存方案，没有就不填&gt;]</span><br><span class="line">&quot;Colour0&quot;=&quot;255,255,255&quot;</span><br><span class="line">&quot;Colour1&quot;=&quot;255,255,255&quot;</span><br><span class="line">&quot;Colour2&quot;=&quot;51,51,51&quot;</span><br><span class="line">&quot;Colour3&quot;=&quot;85,85,85&quot;</span><br><span class="line">&quot;Colour4&quot;=&quot;0,0,0&quot;</span><br><span class="line">&quot;Colour5&quot;=&quot;0,255,0&quot;</span><br><span class="line">&quot;Colour6&quot;=&quot;77,77,77&quot;</span><br><span class="line">&quot;Colour7&quot;=&quot;85,85,85&quot;</span><br><span class="line">&quot;Colour8&quot;=&quot;255,43,43&quot;</span><br><span class="line">&quot;Colour9&quot;=&quot;255,85,85&quot;</span><br><span class="line">&quot;Colour10&quot;=&quot;152,251,152&quot;</span><br><span class="line">&quot;Colour11&quot;=&quot;85,255,85&quot;</span><br><span class="line">&quot;Colour12&quot;=&quot;240,230,140&quot;</span><br><span class="line">&quot;Colour13&quot;=&quot;255,255,85&quot;</span><br><span class="line">&quot;Colour14&quot;=&quot;205,133,63&quot;</span><br><span class="line">&quot;Colour15&quot;=&quot;135,206,235&quot;</span><br><span class="line">&quot;Colour16&quot;=&quot;255,222,173&quot;</span><br><span class="line">&quot;Colour17&quot;=&quot;255,85,255&quot;</span><br><span class="line">&quot;Colour18&quot;=&quot;255,160,160&quot;</span><br><span class="line">&quot;Colour19&quot;=&quot;255,215,0&quot;</span><br><span class="line">&quot;Colour20&quot;=&quot;245,222,179&quot;</span><br><span class="line">&quot;Colour21&quot;=&quot;255,255,255&quot;</span><br></pre></td></tr></table></figure><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><p>在设置中依次点击：<code>Window → Appearance → Font settings: Change……</code></p><p>console，粗体，10</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202501161133280.png" alt="console，粗体，10"></p><h2 id="按键设置"><a href="#按键设置" class="headerlink" title="按键设置"></a>按键设置</h2><p>解决大部分键位映射的问题</p><ol><li><p>将 “The Function keys and keypad” 设置更改为 **”Xterm R6”**。</p></li><li><p>将 “Shift&#x2F;Ctrl&#x2F;Alt with the arrow keys” 设置更改为 **”xterm-style bitmap”**。</p></li></ol><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202501161131787.png" alt="The Function keys and keypad"></p><h2 id="FileZilla配置"><a href="#FileZilla配置" class="headerlink" title="FileZilla配置"></a>FileZilla配置</h2><ul><li><p>界面设置：编辑 → 设置 → 界面 → 布局 → 文件和目录面板布局：宽屏</p></li><li><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202508271637967.png" alt="页面布局配置"></p></li><li><p>链接配置：左上角打开站点管理器 → 设置协议SFTP → 服务器+端口(通常为22) → 用户名+密码</p></li><li><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202508271640778.png" alt="链接配置"></p></li></ul><h2 id="Tmux配置"><a href="#Tmux配置" class="headerlink" title="Tmux配置"></a>Tmux配置</h2><p>安装Tmux界面美化: <a href="https://github.com/gpakosz/.tmux">https://github.com/gpakosz/.tmux</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/gpakosz/.tmux.git</span><br><span class="line"><span class="built_in">ln</span> -s -f .tmux/.tmux.conf</span><br><span class="line"><span class="built_in">cp</span> .tmux/.tmux.conf.local .</span><br></pre></td></tr></table></figure><h3 id="鼠标协助"><a href="#鼠标协助" class="headerlink" title="鼠标协助"></a>鼠标协助</h3><p>找到 <code>.tmux.conf.local</code>文件修改Tmux设置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim .tmux.conf.local</span><br></pre></td></tr></table></figure><p>把 <code>set -g mouse on</code> 这一行取消注释即可</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># start with mouse mode enabled</span><br><span class="line">set -g mouse on</span><br></pre></td></tr></table></figure><h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p>Tmux界面:</p><table><thead><tr><th><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202501161140104.png" alt="Tmux界面1"></th><th><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202501161157725.png" alt="Tmux界面2"></th></tr></thead></table><p>bash界面：</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202501161142782.png" alt="bash界面"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://blog.csdn.net/Pan_peter/article/details/124510524">Linux——putty颜色设置【如何改变颜色】-CSDN博客</a></li><li><a href="https://github.com/AlexAkulov/putty-color-themes">GitHub - AlexAkulov&#x2F;putty-color-themes: PuTTY Color Themes</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ssh%E5%B7%A5%E5%85%B7&quot;&gt;SSH工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E9%85%8D%E8%89%B2%E6%96%B9%E6%A1%88&quot;&gt;配色方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E5</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【随笔】如何克服拖延症？</title>
    <link href="https://zade23.github.io/2024/12/17/%E5%A6%82%E4%BD%95%E5%85%8B%E6%9C%8D%E6%8B%96%E5%BB%B6%E7%97%87%EF%BC%9F/"/>
    <id>https://zade23.github.io/2024/12/17/%E5%A6%82%E4%BD%95%E5%85%8B%E6%9C%8D%E6%8B%96%E5%BB%B6%E7%97%87%EF%BC%9F/</id>
    <published>2024-12-17T03:47:30.000Z</published>
    <updated>2024-12-17T07:10:10.479Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%8B%96%E5%BB%B6">为什么会拖延？</a></li><li><a href="#%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95">处理方法</a><ul><li><a href="#%E8%B0%83%E5%8A%A8%E6%83%85%E7%BB%AA">调动情绪</a></li><li><a href="#%E5%A4%A7%E4%BD%AC%E4%BB%AC%E7%9A%84%E5%BB%BA%E8%AE%AE">大佬们的建议</a></li></ul></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li><li><a href="#%E7%9B%B8%E5%85%B3%E5%8F%82%E8%80%83">相关参考</a></li></ul><hr><h2 id="为什么会拖延？"><a href="#为什么会拖延？" class="headerlink" title="为什么会拖延？"></a>为什么会拖延？</h2><p>大部分情况下的拖延因素来源于“畏难情绪”。</p><p>通常，被拖延的任务要么是重要的任务，要么是比较困难的任务。面对这样的任务，我们会在大脑中放大这个问题的困难程度，放大的原因在于：不熟悉。</p><p>除了拖延症，此前张朝阳还谈起过如何摆脱焦虑的困扰。他介绍称：“在心理学上有一个像物理学里的牛顿定律一样的定律，就是当我们想要去解决焦虑的时候，焦虑就会被放大。所以面对焦虑的时候不要回避，不去解决。而去接受、无视。”</p><h2 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h2><h3 id="调动情绪"><a href="#调动情绪" class="headerlink" title="调动情绪"></a>调动情绪</h3><p>第一步，收集信息。</p><p>信息收集的过程是熟悉任务的过程。在收集的同时，和自己进行“对话”</p><blockquote><p>“完成这个事是需要这个、需要那个……”<br>“这个跟那个之间有什么关系……”</p></blockquote><p>通过这样的方式，让自己的大脑神经元被充分调动，让自己excited。当情绪调动起来了，一鼓作气的将它完成。</p><h3 id="大佬们的建议"><a href="#大佬们的建议" class="headerlink" title="大佬们的建议"></a>大佬们的建议</h3><ol><li><strong>不做过度的准备</strong>（不需要找个舒服环境再开始工作。先完成，再完美，完善的过程问题会越来越多，最终杀死了灵感和信心）</li><li><strong>最难的事情，提前做</strong>（难做的事情放在早上先做）</li><li><strong>不要中途休息</strong>（最好不要有思维的中断，有思路的事情一鼓作气解决）</li><li><strong>不要抱有太强的目标感</strong>（经历只能参考，不能复制。在过程中见招拆招，遇到问题解决问题）</li><li><strong>事情一件一件做</strong>（按照难易程度划分，从难往易一件一件解决）</li><li><strong>拖延也要有度</strong>（有最晚启动时间底线）</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>深度学习领域大牛李沐老师，在上海交通大学进行讲话就提到了：“<strong>找到强烈的动机。</strong>”</p><p>在这里同时分享一句我个人很喜欢的一句话(同样出自李沐老师)：“<strong>一个很好的创业人或者CEO，他一定是理想主义者兼实践者。</strong>”</p><p>我的理解是：坚信自己最终的理想是正确的，同时脚踏实地一步一步干出成绩来。</p><p>下面的这句话有同样的含义：</p><blockquote><p>“<strong>尽早确立人生价值观，无论什么情绪来了，都按照价值观坚定的、积极的生活和工作。</strong>” ——张朝阳</p></blockquote><p>一句话：找到你内心最想做的事情，追随你的内心。</p><h2 id="相关参考"><a href="#相关参考" class="headerlink" title="相关参考"></a>相关参考</h2><ul><li><a href="https://www.bilibili.com/video/BV1JG4y197gS/">张朝阳谈摆脱拖延的方法：拖延的原因在于不熟悉</a></li><li><a href="https://www.bilibili.com/video/BV1zmymYHERs/">杰出系友专访|@BosonAI李沐：找到强烈的动机</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%8B%96%E5%BB%B6&quot;&gt;为什么会拖延？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【DSA】LeetCode_Hot100</title>
    <link href="https://zade23.github.io/2024/10/31/%E3%80%90DSA%E3%80%91LeetCode-Hot100/"/>
    <id>https://zade23.github.io/2024/10/31/%E3%80%90DSA%E3%80%91LeetCode-Hot100/</id>
    <published>2024-10-31T02:34:32.000Z</published>
    <updated>2024-10-31T03:28:56.597Z</updated>
    
    
    
    
    <category term="数据结构和算法" scheme="https://zade23.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="LeetCode" scheme="https://zade23.github.io/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>模型训练库缺失 ImportError: No xformers</title>
    <link href="https://zade23.github.io/2024/07/03/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%BA%93%E7%BC%BA%E5%A4%B1-ImportError-No-xformers/"/>
    <id>https://zade23.github.io/2024/07/03/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%BA%93%E7%BC%BA%E5%A4%B1-ImportError-No-xformers/</id>
    <published>2024-07-03T12:03:21.000Z</published>
    <updated>2024-07-03T12:08:56.675Z</updated>
    
    <content type="html"><![CDATA[<h3 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h3><p>借助Lora训练Diffusion模型的时候，出现了报错：</p><p><code>ImportError: No xformers</code></p><h3 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h3><p>安装对应版本的Transformer模型即可解决问题，参考：<a href="https://github.com/Akegarasu/lora-scripts/issues/422#issuecomment-2127945481">https://github.com/Akegarasu/lora-scripts/issues/422#issuecomment-2127945481</a></p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>找到当前运行训练任务的机器，确定对应的版本：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">pirnt(torch.__version__)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2.3</span><span class="number">.1</span> + cu121</span><br></pre></td></tr></table></figure><p>从输出定位 <strong>torch版本</strong> 和 <strong>cuda版本</strong>，从 <a href="https://github.com/facebookresearch/xformers?tab=readme-ov-file#installing-xformers">https://github.com/facebookresearch/xformers?tab=readme-ov-file#installing-xformers</a> 找 torch + cuda + xformers 三者关系都能对应上的版本。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cuda 12.1 version</span></span><br><span class="line">pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure><p>安装成功，问题解决。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;发现问题&quot;&gt;&lt;a href=&quot;#发现问题&quot; class=&quot;headerlink&quot; title=&quot;发现问题&quot;&gt;&lt;/a&gt;发现问题&lt;/h3&gt;&lt;p&gt;借助Lora训练Diffusion模型的时候，出现了报错：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ImportError: No xfo</summary>
      
    
    
    
    <category term="Deeplearning" scheme="https://zade23.github.io/categories/Deeplearning/"/>
    
    
    <category term="conda" scheme="https://zade23.github.io/tags/conda/"/>
    
    <category term="environment" scheme="https://zade23.github.io/tags/environment/"/>
    
  </entry>
  
  <entry>
    <title>【阅读】Ilya的论文阅读清单</title>
    <link href="https://zade23.github.io/2024/05/27/%E3%80%90%E9%98%85%E8%AF%BB%E3%80%91Ilya%E7%9A%84%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%B8%85%E5%8D%95/"/>
    <id>https://zade23.github.io/2024/05/27/%E3%80%90%E9%98%85%E8%AF%BB%E3%80%91Ilya%E7%9A%84%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%B8%85%E5%8D%95/</id>
    <published>2024-05-27T06:35:39.000Z</published>
    <updated>2024-05-27T07:01:34.542Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D">背景介绍</a></li><li><a href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9">主要内容</a><ul><li><a href="#%E6%A0%B8%E5%BF%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%9B%E6%96%B0">核心神经网络创新</a></li><li><a href="#%E4%B8%93%E4%B8%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8">专业神经网络应用</a></li><li><a href="#%E7%90%86%E8%AE%BA%E8%A7%81%E8%A7%A3%E5%92%8C%E5%8E%9F%E5%88%99%E6%80%A7%E6%96%B9%E6%B3%95">理论见解和原则性方法</a></li><li><a href="#%E8%B7%A8%E5%AD%A6%E7%A7%91%E5%92%8C%E6%A6%82%E5%BF%B5%E7%A0%94%E7%A9%B6">跨学科和概念研究</a></li><li><a href="#%E6%95%88%E7%8E%87%E5%92%8C%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7%E6%8A%80%E6%9C%AF">效率和可扩展性技术</a></li><li><a href="#%E6%95%99%E6%9D%90%E5%92%8C%E6%95%99%E7%A8%8B">教材和教程</a></li></ul></li></ul><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>Ilya Sutskever 的论文清单：<a href="https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE?source=post_page-----3bd4c9f8e927--------------------------------">30u30</a></p><p>Ilya Sutskever 是 Hinton 的大弟子，OpenAI的联合创始人兼首席科学家。</p><p>以下是他推荐的论文清单，他认为阅读完这些内容之后就可以了解AI领域90%的内容</p><h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><h3 id="核心神经网络创新"><a href="#核心神经网络创新" class="headerlink" title="核心神经网络创新"></a>核心神经网络创新</h3><ol><li><a href="https://arxiv.org/abs/1409.2329?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Recurrent Neural Network Regularization</a> - Enhancement to LSTM units for better overfitting prevention.<br>递归神经网络正则化 - 增强了 LSTM 单元，以更好地防止过拟合。</li><li><a href="https://arxiv.org/abs/1506.03134?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Pointer Networks</a> - Novel architecture for solving problems with discrete token outputs.<br> Pointer Networks - 用于解决离散令牌输出问题的新颖架构.</li><li><a href="https://arxiv.org/abs/1512.03385?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Deep Residual Learning for Image Recognition</a> - Improvements for training very deep networks through residual learning.<br> 用于图像识别的深度残差学习 - 改进了通过残差学习训练非常深度的网络。</li><li><a href="https://arxiv.org/abs/1603.05027?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Identity Mappings in Deep Residual Networks</a> - Enhancements to deep residual networks through identity mappings.<br> 深度残差网络中的身份映射 - 通过身份映射增强深度残差网络。</li><li><a href="https://arxiv.org/abs/1512.02595?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Neural Turing Machines</a> - Combining neural networks with external memory resources for enhanced algorithmic tasks.<ul><li>将神经网络与外部内存资源相结合，以增强算法任务。</li></ul></li><li><a href="https://arxiv.org/abs/1706.03762?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Attention Is All You Need</a> - Introducing the Transformer architecture solely based on attention mechanisms.<br> Attention Is All You Need - 介绍完全基于注意力机制的 Transformer 架构。</li></ol><h3 id="专业神经网络应用"><a href="#专业神经网络应用" class="headerlink" title="专业神经网络应用"></a>专业神经网络应用</h3><ul><li><a href="https://arxiv.org/abs/1511.07122?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Multi-Scale Context Aggregation by Dilated Convolutions</a> - A convolutional network module for better semantic segmentation.<br> Multi-Scale Context Aggregation by Dilated Convolutions - 一个卷积网络模块，用于更好的语义分割.</li><li><a href="https://arxiv.org/abs/1409.0473?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Neural Machine Translation by Jointly Learning to Align and Translate</a> - A model improving translation by learning to align and translate concurrently.<br> Neural Machine Translation by Joint Learning to Align and Translation - 一种通过学习同时对齐和翻译来改进翻译的模型.</li><li><a href="https://arxiv.org/abs/1704.01212?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Neural Message Passing for Quantum Chemistry</a> - A framework for learning on molecular graphs for quantum chemistry.<br> Neural Message Passing for Quantum Chemistry - 量子化学分子图学习框架.</li><li><a href="https://arxiv.org/abs/1806.01822?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Relational RNNs</a> - Enhancement to standard memory architectures integrating relational reasoning capabilities.Theoretical and Principled Approaches<br> 关系 RNN - 增强了集成关系推理功能的标准内存架构。理论和原则方法</li><li><a href="https://arxiv.org/abs/1512.02595?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Deep Speech 2: End-to-End Speech Recognition in English and Mandarin</a> - Deep learning system for speech recognition.<br> Deep Speech 2： End-to-End Speech Recognition in English and Mandarin -用于语音识别的深度学习系统.</li><li><a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">ImageNet Classification with Deep CNNs</a> - Convolutional neural network for classifying large-scale image data.<br> ImageNet Classification with Deep CNNs - 用于对大规模图像数据进行分类的卷积神经网络.</li><li><a href="https://arxiv.org/abs/1611.02731?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Variational Lossy Autoencoder</a> - Combines VAEs and autoregressive models for improved image synthesis.<br> 变分有损自动编码器 - 结合 VAE 和自回归模型以改进图像合成。</li><li><a href="https://arxiv.org/abs/1706.01427?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">A Simple NN Module for Relational Reasoning</a> - A neural module designed to improve relational reasoning in AI tasks.<br> 用于关系推理的简单神经网络模块 - 旨在改进 AI 任务中关系推理的神经模块.</li></ul><h3 id="理论见解和原则性方法"><a href="#理论见解和原则性方法" class="headerlink" title="理论见解和原则性方法"></a>理论见解和原则性方法</h3><ul><li><a href="https://arxiv.org/abs/1511.06391?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Order Matters: Sequence to sequence for sets</a> - Investigating the impact of data order on model performance.<br> Order Matters： Sequence to sequence for sets - 调查数据顺序对模型性能的影响。</li><li><a href="https://arxiv.org/abs/2001.08361?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Scaling Laws for Neural LMs</a> - Empirical study on the scaling laws of language model performance.<br> Scaling Laws for Neural LMs -语言模型性能的缩放规律的实证研究.</li><li><a href="https://arxiv.org/abs/math/0406077?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">A Tutorial Introduction to the Minimum Description Length Principle</a> - Tutorial on the MDL principle in model selection and inference.<br> 最小描述长度原则教程简介 - 模型选择和推理中的MDL原理教程.</li><li><a href="https://www.cs.toronto.edu/~hinton/absps/colt93.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Keeping Neural Networks Simple by Minimizing the Description Length of the Weights</a> - Method to improve neural network generalization by minimizing weight description length.<br> 通过最小化权重的描述长度来保持神经网络的简单性 - 通过最小化权重描述长度来提高神经网络泛化的方法。</li><li><a href="https://pdfs.semanticscholar.org/e758/b579456545f8691bbadaf26bcd3b536c7172.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Machine Super Intelligence DissertationMachine Super Intelligence Dissertation</a> - Study on optimal behavior of agents in computable environments.<br> 机器 超级 智能 论文Machine Super Intelligence Dissertation - 研究智能体在可计算环境中的最优行为。</li><li><a href="https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">PAGE 434 onwards: Komogrov Complexity</a> - Comprehensive exploration of Kolmogorov complexity, discussing its mathematical foundations and implications for fields like information theory and computational complexity.<br> 第434页起：科莫格罗夫复杂性 - 全面探索柯尔莫戈罗夫复杂性，讨论其数学基础以及对信息论和计算复杂性等领域的影响。</li></ul><h3 id="跨学科和概念研究"><a href="#跨学科和概念研究" class="headerlink" title="跨学科和概念研究"></a>跨学科和概念研究</h3><ul><li><a href="https://arxiv.org/abs/1405.6903?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton</a> - Study on complexity in closed systems using cellular automata.<br> Quantifying the Rise and Fall of Complexity in Closed Systems： The Coffee Automaton - 使用元胞自动机研究封闭系统中的复杂性.</li></ul><h3 id="效率和可扩展性技术"><a href="#效率和可扩展性技术" class="headerlink" title="效率和可扩展性技术"></a>效率和可扩展性技术</h3><ul><li><a href="https://arxiv.org/abs/1811.06965?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a> - A method for efficient training of large-scale neural networks.<br> GPipe： Efficient Training of Giant Neural Networks using Pipeline Parallelism - 一种高效训练大规模神经网络的方法.</li></ul><h3 id="教材和教程"><a href="#教材和教程" class="headerlink" title="教材和教程"></a>教材和教程</h3><ul><li><a href="https://cs231n.github.io/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">CS231n: Convolutional Neural Networks for Visual Recognition</a> - Stanford University course on CNNs for visual recognition.<br> CS231n：用于视觉识别的卷积神经网络 - 斯坦福大学视觉识别 CNN 课程。</li><li><a href="https://nlp.seas.harvard.edu/annotated-transformer/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">The Annotated Transformer</a> - Annotated, line-by-line implementation of the Transformer paper. Code is available <a href="https://github.com/harvardnlp/annotated-transformer/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">here</a>.<br> The Annotated Transformer - Transformer 论文的带注释的逐行实现.代码可在此处获得。</li><li><a href="https://scottaaronson.blog/?p=762&utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">The First Law of Complexodynamics</a> - Blog post discussing the measure of system complexity in computational terms.<br> The First Law of Complexodynamics - 讨论计算术语中系统复杂性度量的博客文章.</li><li><a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">The Unreasonable Effectiveness of RNNs</a> - Blog post demonstrating the versatility of RNNs.<br> RNN 的不合理有效性 - 展示 RNN 多功能性的博客文章.</li><li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=the-mysterious-ai-reading-list-ilya-sutskever-s-recommendations">Understanding LSTM Networks</a> - Blog post providing a detailed explanation of LSTM networks.<br> 了解 LSTM 网络 - 博客文章提供了 LSTM 网络的详细说明。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D&quot;&gt;背景介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9&quot;&gt;主要内容&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【随笔】关于个人成长的思考</title>
    <link href="https://zade23.github.io/2024/05/10/%E3%80%90%E9%9A%8F%E7%AC%94%E3%80%91%E5%85%B3%E4%BA%8E%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <id>https://zade23.github.io/2024/05/10/%E3%80%90%E9%9A%8F%E7%AC%94%E3%80%91%E5%85%B3%E4%BA%8E%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF%E7%9A%84%E6%80%9D%E8%80%83/</id>
    <published>2024-05-10T03:05:52.000Z</published>
    <updated>2024-05-10T07:26:17.273Z</updated>
    
    <content type="html"><![CDATA[<p>标题相关内容未想好，就先空着吧。</p><p>本篇内容是一篇关于学习、成长、阶级跨越的思考……</p><p>起因是这一篇父亲写给女儿的信<a href="https://zhuanlan.zhihu.com/p/463715925">《阶层跨越》</a> 。</p><p>上一次阅读是在2022年，当时也正是因为这篇内容关注了作者。</p><p>就在昨天重新整理知乎关注的过程中，重新理解了一下这篇文章，感觉和上一次阅读有了完全不一样的体会。</p><p>上一次阅读的时候我还是研三在读，对于工作、领导、责任的感受不深。</p><p>现如今已经工作两年，对于之前不理解的内容和当时“感觉已经理解”的内容由有了不一样的体会。</p><p>也是。</p><p>屁股决定脑袋。</p><p>如果以后再看，可能还会有更不同的看法吧。</p><h2 id="观点陈述"><a href="#观点陈述" class="headerlink" title="观点陈述"></a>观点陈述</h2><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202405101125766.png" width="500" height="600"><p>得益于作者清晰的条理，AI总结的结果也非常清晰。</p><p>我通过这些年的经历结合上面提到的论点做出一些说明。</p><h3 id="情绪稳定"><a href="#情绪稳定" class="headerlink" title="情绪稳定"></a>情绪稳定</h3><p>人们常说的情绪稳定是面对打击和挫折时候的情绪。上面作者提到的“正确面对批评和挫折”，同样在今年黄仁勋于斯坦福的讲话中也举例自己年轻时候的端盘子经历以此来鼓励各位学子勇往直前锲而不舍。</p><p>我想说点和他们不同的，是我从自己身上找到的问题：乐极生悲</p><p>比如对于一些事情过度的期待。如果得不到成果还好，而如果得到了就会沾沾自喜和自己给自己思想放假(“这段时间我真辛苦，休息一下吧”)，殊不知很多事情的成功伴随着团队&#x2F;平台&#x2F;导师等一些列因素。</p><p>这样的后果就是，每一次的小阶段成功之后会有一段时间的“产出真空期”，这是和我对自己设立的阶段目标严重不符的。</p><p>正确的做法应该是：理性客观的总结自己在事件和项目中的贡献，分析自己的改变，为什么可以做到这些改变，自己还有哪些不足并应该如何改正…………短暂的整理心情(平复心情)后，重新上路，追求下一个目标。</p><p>如范仲淹在《岳阳楼记》中所说：“不以物喜不以己悲”</p><h3 id="支持同事和领导"><a href="#支持同事和领导" class="headerlink" title="支持同事和领导"></a>支持同事和领导</h3><p>在研究生期间，导师给了我一个算法证明相关的课题。</p><p>众所周知，证明 + 算法。看似是非常高大上的课题，实则是枯燥乏味且很难获得成就感和反馈的，我很长一段时间都在枯燥的推公式和自我怀疑中度过，不可否认有一大部分的根源来自于能力不足。</p><p>在2019-2021年期间，正是AI相关应用爆发的时间段，也眼馋实验室别的同学随便蹭一蹭AI相关就能发文章的情况，就想找导师更换我自己的课题。</p><p>结果当然是失败了。</p><p>于是就开启了长达两年的纠结过程，做不爱做的课题，并且觉得导师太不通情达理了，自己开始做和课题无关的研究并且在宿舍摆烂(好孩子不要学)</p><p>现在想来，是自己在沟通和处理问题方面不成熟。</p><p>如果现在让重新和导师沟通，我会这么做：和导师商量一个关于该课题的最低标准(发几区、发几篇)，然后表示出自己真正感兴趣的领域，并表面在该领域自己也可以发文章(这是沟通必要条件)。</p><p>当时做错的是逃避了沟通，在“负责任”和“支持领导”这两方面都没有成熟思考。</p><h3 id="口才和表达"><a href="#口才和表达" class="headerlink" title="口才和表达"></a>口才和表达</h3><p>再延伸一点，那就是：争取露脸机会</p><p>在高校和公司这样的地方，成熟的架构有成百上千号人，大佬们没有办法记住所有人。</p><p>最好的办法就是争取露脸机会。</p><p>争取到机会之后，勇敢去表现自己的能力和技术水准。</p><p>在技术人员中，有很大一部分的人是不太擅长表述的，他们的工程能力非常突出，但是表达的通常比较啰嗦。</p><p>前段时间听到过一个观点：人生就是一个巨大的推销过程。</p><p>做汇报、述职、做报告，其实就包含了推销自己的能力这个过程。</p><p>为什么在AI火爆的那段时间内，讲好故事的公司能够拿到融资，那是因为讲好故事就是一种“夸张”的推销表达。</p><p>未来希望自己可以培养的能力：<strong>口才</strong> + <strong>表达</strong> + <strong>把握机会的能力</strong></p><h3 id="做事能力和思维能力"><a href="#做事能力和思维能力" class="headerlink" title="做事能力和思维能力"></a>做事能力和思维能力</h3><p>做事能力：业务能力(基本) + 时间管理 + 团队合作(协作和沟通)</p><p>思维能力：超出当前层级的视角 + 学习领导能力</p><p>多年后重新看这篇文章，最区别的感受是要对于“整体架构”的把控。</p><p>原来自己觉得，只用把自己领域做大做强做精尖就可以了。</p><p>现在觉得这其实是很困难的，互联网的知识更新换代非常的快，永远学不完这个领域里所有的知识。</p><p>比较正确的做法应该是：掌握自己领域内最扎实的能力(业务能力) + 扩展知识的广度。</p><p>比如，要设计web端的AI应用，就需要了解前后端的相关技术，是否应该前后端分离，如果涉及到存储，数据库的选型应该是MySQL这种关系型数据库还是NoSQL类的非关系型数据库……对于上下游工作的了解能够让你和上下游更好的协调沟通(如果愿意的话，做个全栈也未尝不可)。</p><p>并且，对各方面技术栈的了解对于未来想做管理也是有帮助的。</p><p>待补充</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;标题相关内容未想好，就先空着吧。&lt;/p&gt;
&lt;p&gt;本篇内容是一篇关于学习、成长、阶级跨越的思考……&lt;/p&gt;
&lt;p&gt;起因是这一篇父亲写给女儿的信&lt;a href=&quot;https://zhuanlan.zhihu.com/p/463715925&quot;&gt;《阶层跨越》&lt;/a&gt; 。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【Git】在README.md中展示视频的方案</title>
    <link href="https://zade23.github.io/2024/04/26/%E3%80%90Git%E3%80%91%E5%9C%A8README-md%E4%B8%AD%E5%B1%95%E7%A4%BA%E8%A7%86%E9%A2%91%E7%9A%84%E6%96%B9%E6%A1%88/"/>
    <id>https://zade23.github.io/2024/04/26/%E3%80%90Git%E3%80%91%E5%9C%A8README-md%E4%B8%AD%E5%B1%95%E7%A4%BA%E8%A7%86%E9%A2%91%E7%9A%84%E6%96%B9%E6%A1%88/</id>
    <published>2024-04-26T03:53:42.000Z</published>
    <updated>2024-04-26T03:58:20.162Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E5%86%85%E5%AE%B9%E4%BB%8B%E7%BB%8D">内容介绍</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E">使用说明</a><ul><li><a href="#github">github</a></li><li><a href="#gitlab">gitlab</a></li><li><a href="#blog%E6%94%AF%E6%8C%81%E7%9A%84html%E6%A0%BC%E5%BC%8F">blog支持的html格式</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li></ul><h2 id="内容介绍"><a href="#内容介绍" class="headerlink" title="内容介绍"></a>内容介绍</h2><p>在 GitHub 和 GitLab 仓库中，通过在 README.md 中展示视频Demo的方式直观的展示项目的效果。</p><p>最后，加上一种HTML形式渲染视频的方案，效果如下：</p><p><video src="https://github.com/zade23/zade23.github.io/assets/53324261/9ef0711b-29eb-4994-b34a-3d9d2152ea9b" controls="controls" width="500" height="300"></video></p><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><h3 id="github"><a href="#github" class="headerlink" title="github"></a>github</h3><blockquote><p>注意：<strong>视频不能超过10m</strong></p></blockquote><p>GitHub 上用将视频提交到 issues 中，此时视频文件将上传到GitHub中并获得一个文件链接，这个链接放置在README中可以被直接渲染成视频。</p><ol><li>上传视频文件至某个 GitHub 项目的 issues 中</li><li>复制链接，放置在README中</li></ol><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404261136499.jpg" alt="上传视频至issues"></p><h3 id="gitlab"><a href="#gitlab" class="headerlink" title="gitlab"></a>gitlab</h3><p>GitLab 可以直接用Markdown图片链接的格式渲染已存放在仓库或 issues 中的视频</p><ol><li>用图片链接的格式直接嵌入视频。<strong>支持格式为 <code>.mp4</code>、<code>.m4v</code>、<code>.mov</code>、<code>.webm</code> 和 <code>.ogv</code></strong></li><li>修改下面代码中视频文件的相对路径</li></ol><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Here&#x27;s a sample video:</span><br><span class="line"></span><br><span class="line">![<span class="string">Sample Video</span>](<span class="link">img/markdown_video.mp4</span>)</span><br></pre></td></tr></table></figure><blockquote><p>嵌入链接同样可以是已经提到issues中的视频文件链接</p></blockquote><h3 id="blog支持的html格式"><a href="#blog支持的html格式" class="headerlink" title="blog支持的html格式"></a>blog支持的html格式</h3><p>先采用提issues的方式或者上传至仓库的方式将文件上传。</p><ol><li>将下面链接中 <code>src</code> 内的部分改成你的链接即可</li></ol><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">video</span> <span class="attr">src</span>=<span class="string">&quot;movie.mp4.mp4&quot;</span> <span class="attr">controls</span>=<span class="string">&quot;controls&quot;</span> <span class="attr">width</span>=<span class="string">&quot;500&quot;</span> <span class="attr">height</span>=<span class="string">&quot;300&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">video</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://docs.gitlab.cn/jh/user/markdown.html#%E8%A7%86%E9%A2%91">极狐文档中心-Markdown-视频</a></li><li><a href="http://t.csdnimg.cn/ehxyq">GitHub 仓库的 README 直接播放视频</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E5%86%85%E5%AE%B9%E4%BB%8B%E7%BB%8D&quot;&gt;内容介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E&quot;&gt;使用说明&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    
    <category term="Git" scheme="https://zade23.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>【Git】一个流畅的开源贡献流程</title>
    <link href="https://zade23.github.io/2024/04/25/%E3%80%90Git%E3%80%91%E4%B8%80%E4%B8%AA%E6%B5%81%E7%95%85%E7%9A%84%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E6%B5%81%E7%A8%8B/"/>
    <id>https://zade23.github.io/2024/04/25/%E3%80%90Git%E3%80%91%E4%B8%80%E4%B8%AA%E6%B5%81%E7%95%85%E7%9A%84%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E6%B5%81%E7%A8%8B/</id>
    <published>2024-04-25T04:03:15.000Z</published>
    <updated>2024-04-28T03:28:58.250Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>由本人的有道云笔记搬运到个人网站，创作日期：2023年3月20日</p></blockquote><ul><li><a href="#%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%BC%80%E6%BA%90">教练……我想开源</a></li><li><a href="#github%E5%BC%80%E6%BA%90%E4%BB%93%E5%BA%93%E5%B7%A5%E4%BD%9C%E6%B5%81">github开源仓库工作流</a></li><li><a href="#%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E6%83%B3%E8%BF%9B%E8%A1%8C%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE">如果我们想进行开源贡献</a></li><li><a href="#paddle%E9%A1%B9%E7%9B%AE">Paddle项目</a><ul><li><a href="#%E6%96%87%E6%A1%A3%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97">文档贡献指南</a><ul><li><a href="#%E7%AC%AC%E4%B8%80%E6%AD%A5fork%E4%BB%93%E5%BA%93%E5%B9%B6clone%E5%88%B0%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD">第一步：Fork仓库并Clone到本地加载</a></li><li><a href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5fork%E4%BB%93%E5%BA%93%E5%B9%B6clone%E5%88%B0%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD">第二步：Fork仓库并Clone到本地加载</a></li><li><a href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B8%8B%E8%BD%BDpre-commit%E5%B7%A5%E5%85%B7%E4%B8%8B%E8%BD%BD%E8%BF%87%E5%B0%B1%E4%B8%8D%E7%94%A8%E5%86%8D%E4%B8%8B%E4%BA%86">第三步：下载pre-commit工具（下载过就不用再下了）</a></li><li><a href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E5%8D%95%E6%AC%A1%E4%BF%AE%E6%94%B9%E5%B9%B6%E6%8F%90%E4%BA%A4%E9%83%BD%E8%A6%81%E8%BF%90%E8%A1%8Cpre-commit%E8%BF%9B%E8%A1%8C%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95">第四步：单次修改并提交都要运行pre-commit进行单元测试</a><ul><li><a href="#%E6%8F%90%E4%BA%A4commit">提交：commit</a></li></ul></li><li><a href="#%E7%AC%AC%E4%BA%94%E6%AD%A5push">第五步：push</a></li><li><a href="#%E7%AC%AC%E5%85%AD%E6%AD%A5review--merge">第六步：review &amp; merge</a></li><li><a href="#%E5%B0%8F%E6%8F%92%E6%9B%B2checkprtemplate-%E4%B8%80%E5%AE%9A%E8%A6%81%E8%A7%84%E8%8C%83">小插曲：CheckPRTemplate 一定要规范</a></li></ul></li></ul></li><li><a href="#gradio%E9%A1%B9%E7%9B%AE">Gradio项目</a></li><li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li></ul><h2 id="教练……我想开源"><a href="#教练……我想开源" class="headerlink" title="教练……我想开源"></a>教练……我想开源</h2><p>一直想参加一个开源项目，丰富自己GitHub账号头衔的同时还能学到一些知识。目前定位到了两个自己非常感兴趣的项目</p><ol><li>（国内项目）Paddle：百度飞桨深度学习框架</li><li>（国际项目）Gradio：用Python构建机器学习网页APP<br>在项目主页的 Issues 提出自己的问题</li></ol><h2 id="github开源仓库工作流"><a href="#github开源仓库工作流" class="headerlink" title="github开源仓库工作流"></a>github开源仓库工作流</h2><blockquote><p>参考<a href="https://nvie.com/posts/a-successful-git-branching-model/">《A successful Git branching model》</a><br>Remote（main&#x2F;）：所有人都共享的代码仓库</p></blockquote><h2 id="如果我们想进行开源贡献"><a href="#如果我们想进行开源贡献" class="headerlink" title="如果我们想进行开源贡献"></a>如果我们想进行开源贡献</h2><ul><li>第一步就是建立一个“feature branch”。目前在Local上，main branch 和 feature branch 上面的内容都是一致的。当使用checkout命令后，硬盘会同步git指定branch下所有的源文件（切换就会改变硬盘当下空间内部的文件）<br>如何正确提Issues<br> 在提Issues之前，一定要提前用关键字搜索看一下你想提出的问题是否已经存在。确定不存在后再进行提问</li></ul><h2 id="Paddle项目"><a href="#Paddle项目" class="headerlink" title="Paddle项目"></a>Paddle项目</h2><h3 id="文档贡献指南"><a href="#文档贡献指南" class="headerlink" title="文档贡献指南"></a>文档贡献指南</h3><p>以最近的一次合并提交为例：本次提交是添加了Tensor文件夹下的十个说明文档。</p><h4 id="第一步：Fork仓库并Clone到本地加载"><a href="#第一步：Fork仓库并Clone到本地加载" class="headerlink" title="第一步：Fork仓库并Clone到本地加载"></a>第一步：Fork仓库并Clone到本地加载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/&lt;USERNAME&gt;/docs</span><br><span class="line"><span class="built_in">cd</span> docs</span><br></pre></td></tr></table></figure><h4 id="第二步：Fork仓库并Clone到本地加载"><a href="#第二步：Fork仓库并Clone到本地加载" class="headerlink" title="第二步：Fork仓库并Clone到本地加载"></a>第二步：Fork仓库并Clone到本地加载</h4><p>docs 目前使用 Git 流分支模型进行开发，测试，发行和维护。<br>所有的 feature 和 bug fix 的开发工作都应该在一个新的分支上完成，一般从 develop 分支上创建新分支。<br>使用 <code>git checkout -b</code> 创建并切换到新分支。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git status  <span class="comment">#查看一下当前分支目录是否clean</span></span><br><span class="line">git checkout -b &lt;创建并切换到的分支名称&gt;</span><br></pre></td></tr></table></figure><h4 id="第三步：下载pre-commit工具（下载过就不用再下了）"><a href="#第三步：下载pre-commit工具（下载过就不用再下了）" class="headerlink" title="第三步：下载pre-commit工具（下载过就不用再下了）"></a>第三步：下载pre-commit工具（下载过就不用再下了）</h4><p>一种检查模板格式是否匹配项目格式的预提交工具。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pre-commit</span><br><span class="line">pre-commit install</span><br></pre></td></tr></table></figure><h4 id="第四步：单次修改并提交都要运行pre-commit进行单元测试"><a href="#第四步：单次修改并提交都要运行pre-commit进行单元测试" class="headerlink" title="第四步：单次修改并提交都要运行pre-commit进行单元测试"></a>第四步：单次修改并提交都要运行pre-commit进行单元测试</h4><ol><li>通过指令 git status 进行状态的检查</li><li>通过 git add 将内容添加进准备提交的区域</li></ol><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/1714027390144.jpg" alt="git status"></p><blockquote><p>上面的状态空间中显示我 9 次修改中有 1 次进入了“暂存区”，此时就要使用pre-commit指令进行单元测试</p></blockquote><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/1714027493043.jpg" alt="pre-commit"></p><blockquote><p>上面在运行了pre-commit之后，除了红色以外区域显示是通过的部分。红色部分说明没有通过单元测试，这个报错说明Linux系统和Win系统的换行符不统一导致的格式问题，一般这种情况下pre-commit会自己进行修复，所以重新提交就可以解决</p></blockquote><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/1714027499063.jpg" alt="pre-commit"></p><blockquote><p>上面在进行了一次性的提交之后，pre-commit一次性将所有的文件进行了检查和修改，之后再进行一次 git add –update 就可以将更新修改后的文件合并至文件的缓存区内。</p></blockquote><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251451164.jpg" alt="git add --update"></p><blockquote><p>解决步骤如上</p></blockquote><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251451889.jpg" alt="pre-commit"></p><blockquote><p>在进行一次提交之后就可以看到所有单元测试已经通过了</p></blockquote><p>在单元测试全部通过之后，可以正式填写提交说明了：</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251452892.jpg" alt="git commit"></p><blockquote><p>上面我提出的说明是“修改文档”。显示有 9 个文件被修改了， 20 行新增代码， 22 行删减代码。</p></blockquote><h5 id="提交：commit"><a href="#提交：commit" class="headerlink" title="提交：commit"></a>提交：commit</h5><p><strong>之所以要运行 <code>pre-commit</code>  就是要为后面要执行的commit操作避免提前的冲突和麻烦</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m <span class="string">&quot;fix/add xxxx&quot;</span></span><br></pre></td></tr></table></figure><h4 id="第五步：push"><a href="#第五步：push" class="headerlink" title="第五步：push"></a>第五步：push</h4><p>先确保已经同步过原始仓库的最新代码 <a href="https://github.com/PaddlePaddle/docs">https://github.com/PaddlePaddle/docs</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">➜  git remote</span><br><span class="line">origin</span><br><span class="line">➜  git remote -v</span><br><span class="line">origin  https://github.com/USERNAME/docs (fetch)</span><br><span class="line">origin  https://github.com/USERNAME/docs (push)</span><br><span class="line"></span><br><span class="line"><span class="comment"># origin 是 clone 的远程仓库的名字，也就是自己用户名下的 Paddle，接下来创建一个原始 Paddle 的仓库远程主机，命名为 upstream</span></span><br><span class="line">➜  git remote add upstream https://github.com/PaddlePaddle/docs</span><br><span class="line">➜  git remote</span><br><span class="line">&gt;&gt;  origin</span><br><span class="line">&gt;&gt;  upstream</span><br><span class="line">-----------------------------------之前提交过了就可以跳到这一步---------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 upstream 的最新代码并更新当前分支</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 upstream 远程仓库获取最新的代码和提交历史，将本地仓库与远程仓库保持同步。</span></span><br><span class="line">➜  git fetch upstream  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 upstream 远程仓库 develop 分支中获取最新的代码和提交历史，并将其自动合并到当前本地分支。</span></span><br><span class="line">➜  git pull upstream develop </span><br><span class="line"></span><br><span class="line"><span class="comment"># Push 到远程仓库：也就是将本地修改推送到 GitHub 即： https://github.com/USERNAME/docs</span></span><br><span class="line"><span class="comment"># 将本地分支的提交推送到名为origin的远程仓库中的特定分支（&lt;my-pr&gt;）。</span></span><br><span class="line"><span class="comment"># 通过执行此命令，您可以将本地分支的修改上传到远程仓库，使得其他协作者可以查看和访问您的提交。</span></span><br><span class="line">➜  git push origin &lt;my-pr(第二步中取的名字)&gt;</span><br></pre></td></tr></table></figure><h4 id="第六步：review-amp-merge"><a href="#第六步：review-amp-merge" class="headerlink" title="第六步：review &amp; merge"></a>第六步：review &amp; merge</h4><blockquote><p>我的第一次提交 <a href="https://github.com/PaddlePaddle/docs/pull/5747">https://github.com/PaddlePaddle/docs/pull/5747</a><br>几点小的总结：</p></blockquote><ul><li>尽量把自己在做的过程中不确定的内容进行说明</li><li>把疑问的地方进行复现</li><li>每一轮的回复都要进行礼貌性的回答</li><li>尽量把每一版的修改都进行分点的说明，第一做了XXX，第二做了XXXX……</li><li></li></ul><h4 id="小插曲：CheckPRTemplate-一定要规范"><a href="#小插曲：CheckPRTemplate-一定要规范" class="headerlink" title="小插曲：CheckPRTemplate 一定要规范"></a>小插曲：CheckPRTemplate 一定要规范</h4><p>如果希望 Paddle 能够接受你的提交，至少需要满足以下三点：</p><ul><li><p>单元测试通过 —— Docs-NEW</p></li><li><p>文档PR格式检测通过 —— CheckPRTemplate</p></li><li><p>同意签署开源贡献者协议 —— license&#x2F;cla<br>一般Docs-NEW可能需要比较长的时间进行检测，偶尔也需要排队等待。所以这次我以为 CheckPRTemplat 也是一样需要等，但是等了整整一天时间……最后发现其实PR格式不是特别正确（虽然也有人格式不正确但通过了PR格式检测），最终参考 <a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/dev_guides/git_guides/paddle_ci_manual_cn.html#checkprtemplate">checkprtemplate</a> 。修改后的格式如下：</p><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251453294.jpg" alt="Paddle项目开源贡献要求的格式"></p></li></ul><p>修改之后秒过。</p><h2 id="Gradio项目"><a href="#Gradio项目" class="headerlink" title="Gradio项目"></a>Gradio项目</h2><p>一位同学进行的一个非常标准的开源参与流程：</p><ol><li><p>提Issues。在这个过程中以项目管理者角度出发，顺带说明了四点问题：</p><ol><li><strong>是否已存在类似Issue。</strong>I have searched to see if a similar issue already exists.（我已经搜索过是否已经存在类似问题。）</li><li><strong>描述你的问题和想添加的功能。</strong>Is your feature request related to a problem? Please describe.（您的功能请求是否与问题相关？请描述。）</li><li><strong>提出解决方案。</strong>Describe the solution you’d like.（描述您想要的解决方案）</li><li><strong>是否有前情提要。</strong>Additional context.（附加上下文）</li></ol><p> <img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251453976.jpg" alt="提问动机"></p></li><li><p>请求合并Merge。在这个过程中以项目管理者角度出发，顺带说明了四点问题：</p><ol><li>relevant motivation.（相关动机）</li><li>a summary of the change.（总结你做出的更改）</li><li>which issue is fixed.（解决了Issue中的哪一个）</li><li>any additional dependencies that are required for this change.（在本次变更中是否有其他依赖项）</li></ol><p> <img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/202404251454853.jpg" alt="详细描述自己所做的工作"></p></li></ol><hr><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><p>git commit之后，想撤销commit</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --soft HEAD^</span><br></pre></td></tr></table></figure></li><li><p>视频链接</p><ol><li><a href="https://www.bilibili.com/video/BV18T411z7R4/?share_source=copy_web&vd_source=48383e849d4fc23ac2e38278a3df1b87">【如何正确地提github issue？开源项目作者来和你聊聊这个重要技能】</a></li><li><a href="https://www.bilibili.com/video/BV19e4y1q7JJ/?share_source=copy_web&vd_source=48383e849d4fc23ac2e38278a3df1b87">【十分钟学会正确的github工作流，和开源作者们使用同一套流程】</a></li><li><a href="https://www.freecodecamp.org/chinese/news/how-to-make-your-first-pull-request-on-github/">【freeCodeCamp | 如何在 GitHub 提交第一个 pull request】</a></li></ol></li><li><p>AIstudio上持久化安装pip包</p><ol><li>提前运行 <code>cd ~ &amp;&amp; mkdir loca_data &amp;&amp; ln -s local_data.local</code></li></ol></li><li><p><a href="https://www.bilibili.com/video/BV19e4y1q7JJ/?share_source=copy_web&vd_source=48383e849d4fc23ac2e38278a3df1b87">十分钟学会正确的github工作流，和开源作者们使用同一套流程</a></p><blockquote><p>一套开源项目和部分企业都在使用的工作流</p></blockquote></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;由本人的有道云笔记搬运到个人网站，创作日期：2023年3月20日&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%BC%80%E6%BA%90</summary>
      
    
    
    
    <category term="Git Workflow" scheme="https://zade23.github.io/categories/Git-Workflow/"/>
    
    
    <category term="Git" scheme="https://zade23.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>【Unity】破解版安装指北</title>
    <link href="https://zade23.github.io/2024/04/22/%E3%80%90Unity%E3%80%91%E7%A0%B4%E8%A7%A3%E7%89%88%E5%AE%89%E8%A3%85%E6%8C%87%E5%8C%97/"/>
    <id>https://zade23.github.io/2024/04/22/%E3%80%90Unity%E3%80%91%E7%A0%B4%E8%A7%A3%E7%89%88%E5%AE%89%E8%A3%85%E6%8C%87%E5%8C%97/</id>
    <published>2024-04-22T13:27:41.000Z</published>
    <updated>2024-04-22T13:42:52.171Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E4%BB%8B%E7%BB%8D">介绍</a></li><li><a href="#%E7%89%88%E6%9C%AC%E9%80%89%E6%8B%A9">版本选择</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E">使用说明</a></li><li><a href="#%E8%B8%A9%E5%9D%91">踩坑</a></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>个人版的Unity安装通过Unity官网一步一步进行即可。<br>今天我们聊的是：如何安装Unity的完整破解版。</p><p>如果没有许可的Unity项目在重新登录之后会提示如下界面：<br><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/A3c6EYT72l.jpg" alt="没有许可"></p><p>在这个状态下，左右两个选项都无法正常启动项目，那么就需要考虑使用个人版或者破解Unity了。</p><blockquote><p>注意：以下内容仅供用于非营利性的教育和测试目的。</p></blockquote><h2 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h2><p>我当前使用的版本参数如下：</p><ul><li>Unity：2022.3.9f1</li><li>Unity Hub：3.4.2</li></ul><p>关于Unity破解版这里用到以下两个用于破解软件的链接：</p><ul><li><a href="https://github.com/tylearymf/UniHacker">https://github.com/tylearymf/UniHacker</a></li><li><a href="https://github.com/agentbillwh/unilic">https://github.com/agentbillwh/unilic</a></li></ul><p>两个GitHub工程的对应Unity项目的破解关系是：</p><p><strong>UniHacker → Unity Hub</strong><br><strong>unilic → Unity</strong></p><p>正常情况下UniHacker可以同时破解 Unity 和 Unity Hub，由于UniHacker可以破解的Unity版本不能高于2022.2所以我们另外使用unilic破解Unity。</p><p>这样破解就可以使用较新的Unity版本了。</p><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>上述链接中的两个工程都是非常详细的工程，按照<code>READ.md</code>内容一步一步来即可，UniHacker更是打包成了一个<code>.exe</code>文件供用户直接破解。</p><p>UniHacker的破解结束后有两个选项：</p><ul><li>是否登录自己的账号：建议<code>否</code></li><li>是否保持更新：建议<code>否</code></li></ul><p>破解成功后，可打开原始项目。<br><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/img_v3_02a6_ede5a60a-bb44-416f-830e-e3843209257g.jpg" alt="Unity，启动"></p><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><ol><li><p>Unity Hub 版本不能太高</p><p> 如果只破解了Unity而没有破解Unity Hub(或Unity Hub的版本过高，如图中3.7版)则会在打开项目的时候反复弹窗确认登录信息。</p></li></ol><p><img src="https://raw.githubusercontent.com/usingnamespaceX/picture_bed/main/img_v3_02a6_71156aec-81f4-4cef-80d0-a9f51738028g.jpg" alt="版本过高"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%BB%8B%E7%BB%8D&quot;&gt;介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%89%88%E6%9C%AC%E9%80%89%E6%8B%A9&quot;&gt;版本选择&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%BD%BF</summary>
      
    
    
    
    <category term="Unity" scheme="https://zade23.github.io/categories/Unity/"/>
    
    
    <category term="Game Engine" scheme="https://zade23.github.io/tags/Game-Engine/"/>
    
  </entry>
  
  <entry>
    <title>【NLP】RWKV对比Transformer</title>
    <link href="https://zade23.github.io/2024/04/16/%E3%80%90NLP%E3%80%91RWKV%E5%AF%B9%E6%AF%94Transformer/"/>
    <id>https://zade23.github.io/2024/04/16/%E3%80%90NLP%E3%80%91RWKV%E5%AF%B9%E6%AF%94Transformer/</id>
    <published>2024-04-16T03:25:31.000Z</published>
    <updated>2024-04-16T09:01:32.603Z</updated>
    
    <content type="html"><![CDATA[<h3 id="模型的精度问题"><a href="#模型的精度问题" class="headerlink" title="模型的精度问题"></a>模型的精度问题</h3><p>int4? int8? bf16? bf32? float16? float32?</p><h3 id="模型参数文件"><a href="#模型参数文件" class="headerlink" title="模型参数文件"></a>模型参数文件</h3><p>常见的 <code>generation_config.json</code> 文件</p><p>下面的内容来自 Baichuan2-7B-Chat 模型生成器参数文件</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;pad_token_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;bos_token_id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;eos_token_id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;user_token_id&quot;</span><span class="punctuation">:</span> <span class="number">195</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;assistant_token_id&quot;</span><span class="punctuation">:</span> <span class="number">196</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;max_new_tokens&quot;</span><span class="punctuation">:</span> <span class="number">2048</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;temperature&quot;</span><span class="punctuation">:</span> <span class="number">0.3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;top_k&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;top_p&quot;</span><span class="punctuation">:</span> <span class="number">0.85</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;repetition_penalty&quot;</span><span class="punctuation">:</span> <span class="number">1.05</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;do_sample&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;transformers_version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4.29.2&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>下面的内容来自 <code>RWKV/v5-Eagle-7B-HF</code> 模型生成器参数文件</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;chat_format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chatml&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eos_token_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;pad_token_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_window_size&quot;</span><span class="punctuation">:</span> <span class="number">4096</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_new_tokens&quot;</span><span class="punctuation">:</span> <span class="number">4096</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;do_sample&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;top_k&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;top_p&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;repetition_penalty&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;transformers_version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4.31.1&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="半精度？全精度？-指令微调？-chat模型？"><a href="#半精度？全精度？-指令微调？-chat模型？" class="headerlink" title="半精度？全精度？ 指令微调？ chat模型？"></a>半精度？全精度？ 指令微调？ chat模型？</h3><p>HF模型？</p><h3 id="微调方式"><a href="#微调方式" class="headerlink" title="微调方式"></a>微调方式</h3><p>指令微调？全量&#x2F;半精度&#x2F;零样本？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;模型的精度问题&quot;&gt;&lt;a href=&quot;#模型的精度问题&quot; class=&quot;headerlink&quot; title=&quot;模型的精度问题&quot;&gt;&lt;/a&gt;模型的精度问题&lt;/h3&gt;&lt;p&gt;int4? int8? bf16? bf32? float16? float32?&lt;/p&gt;
&lt;h3 </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【NLP】RWKV框架入门</title>
    <link href="https://zade23.github.io/2024/04/15/%E3%80%90NLP%E3%80%91RWKV%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8/"/>
    <id>https://zade23.github.io/2024/04/15/%E3%80%90NLP%E3%80%91RWKV%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8/</id>
    <published>2024-04-15T03:56:48.000Z</published>
    <updated>2024-04-25T07:00:53.080Z</updated>
    
    <content type="html"><![CDATA[<p>全文从以下几个方面展开：</p><ul><li><a href="#rwkv%E6%98%AF%E4%BB%80%E4%B9%88">RWKV是什么</a><ul><li><a href="#%E6%9E%B6%E6%9E%84%E7%BB%84%E6%88%90">架构组成</a></li><li><a href="#%E7%89%B9%E6%AE%8A%E6%80%A7%E5%88%86%E6%9E%90">特殊性分析</a></li></ul></li><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E5%9E%8Brwkv%E5%81%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E5%9F%BA%E5%BA%95%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E7%A0%94">为什么选型RWKV做大语言基底模型的预研</a></li><li><a href="#rwkv%E5%92%8Ctransformer%E7%9A%84%E5%B7%AE%E5%88%AB">RWKV和Transformer的差别</a></li><li><a href="#%E7%BB%93%E6%9E%84%E5%BB%BA%E6%A8%A1">结构建模</a><ul><li><a href="#self-attention">Self-Attention</a></li><li><a href="#multi-head-attention">Multi-Head Attention</a></li><li><a href="#rwkv%E7%BB%93%E6%9E%84">RWKV结构</a></li><li><a href="#%E6%95%88%E6%9E%9C%E8%A1%A8%E7%8E%B07b">效果表现（7B）</a></li><li><a href="#%E7%BB%93%E8%AF%AD">结语</a></li></ul></li></ul><hr><h2 id="RWKV是什么"><a href="#RWKV是什么" class="headerlink" title="RWKV是什么"></a>RWKV是什么</h2><p>RWKV架构是一种针对分布式存储系统的架构设计，主要关注于提高数据的可靠性、可用性和一致性，同时优化性能和扩展性。</p><p>RWKV代表的是Read-Write-Key-Value，这个架构通过分离读（R）和写（W）操作，以及将键（Key）和值（Value）分离，来实现其设计目标。</p><h3 id="架构组成"><a href="#架构组成" class="headerlink" title="架构组成"></a>架构组成</h3><ol><li><strong>读写分离</strong>：RWKV架构中，<strong>读操作</strong> 和 <strong>写操作</strong> 是分开处理的。这意味着系统可以针对读操作进行优化，比如通过缓存机制来提高读取速度，而写操作则可以专注于数据的持久化和一致性保证。</li><li><strong>键值存储</strong>：在这种架构中，键（Key）和值（Value）是分开存储的。键通常包含了定位数据所需的全部信息，而值则是实际的数据内容。这种分离使得系统可以更加灵活地管理数据，比如可以实现键的索引，从而加快查找速度。</li><li><strong>数据分区</strong>：为了提高系统的扩展性，RWKV架构通常会将数据进行分区。每个分区可以独立地进行读写操作，这样可以在不影响整个系统的情况下，对单个分区进行扩展或维护。</li></ol><h3 id="特殊性分析"><a href="#特殊性分析" class="headerlink" title="特殊性分析"></a>特殊性分析</h3><ol><li><strong>高性能</strong>：通过读写分离，RWKV架构能够针对不同的操作类型进行专门的优化。例如，读操作可以通过增加缓存层来提高响应速度，而写操作则可以通过批量处理和日志优化来提高吞吐量。</li><li><strong>高可用性</strong>：RWKV架构通过数据分区和副本机制来保证数据的可用性。即使某个分区发生故障，系统也可以通过其他分区或副本来继续提供服务。</li><li><strong>一致性保证</strong>：在分布式系统中，数据一致性是一个重要的问题。RWKV架构通过写操作的严格控制和一致性协议，比如两阶段提交（2PC）或Paxos、Raft等算法，来确保数据在多个副本之间的一致性。</li><li><strong>扩展性</strong>：由于数据分区的设计，RWKV架构可以很好地支持水平扩展。当系统需要处理更多的数据或请求时，可以通过增加更多的分区来实现。</li><li><strong>灵活性</strong>：键值分离的设计使得RWKV架构在数据管理上具有很高的灵活性。可以根据业务需求，对键进行定制化的索引和查询，从而更好地支持复杂的应用场景。</li></ol><h2 id="为什么选型RWKV做大语言基底模型的预研"><a href="#为什么选型RWKV做大语言基底模型的预研" class="headerlink" title="为什么选型RWKV做大语言基底模型的预研"></a>为什么选型RWKV做大语言基底模型的预研</h2><p>因为：便宜好用（这里的便宜是指算力的便宜）</p><p>到底有多便宜呢？</p><p>上图是RWKV架构模型对比Transformer类架构模型在完成推理任务时的时间复杂度和空间复杂度对比。</p><p>通过复杂度可以看到，RWKV架构模型推理的耗时和内存占用随Tokens(可以简单理解为字数)长度呈线性增长关系。而Transformer类模型则呈幂级数增长关系，如果表现在游戏对话任务中，就是和NPC说的话越多，它回复你的时间就会越久，这也很贴合Transformer模型中的重要结构Attention机制的中文翻译——“注意力”。</p><p>前些日子看到有文章说华为内部开始研究RWKV架构去服务于他们的大语言模型，于是去其官网上一探究竟，发现 <a href="https://stability.ai/">stability.ai</a>（开源AI绘画架构的开发公司）也对RWKV进行了赞助，说明RWKV在架构一定有它的特殊性和优越性，于是决定研究一下。</p><p>早在2023年5月RWKV架构问世就已经，在一众Transformer模型架构的LLM领域下，这是一个使用RNN架构进行模型推理的模型。并且在竞争激烈的大语言模型评测中排到了第八名的成绩。</p><p>长话短说，如果使用RWKV，最希望它能够解决的问题是：<strong>费用问题</strong></p><p>在某上线项目的用户信息采集中，我们发现：玩家其实并不那么care游戏中的AI智不智能(更多的是来看看这个AI是不是一个噱头)，也并没有对于它不能回答自己的奇怪提问而提出不满（注意：这里得到的结果并不具有泛化性，有许多影响这一结果的因素没有考虑，包括但不限于：游戏玩法和用户年龄段画像等）。那么在学术界上的细扣模型智能面板上提升零点几个百分点的性能表现大战就几乎不需要考虑了，与其牺牲更多的开发成本和模型加载成本得到一个智力刚及格的AI，还要被玩家拷打“爸爸的爸爸叫什么~”，不如创造一个弱智吧吧友级别的AI更有节目效果。</p><h2 id="RWKV和Transformer的差别"><a href="#RWKV和Transformer的差别" class="headerlink" title="RWKV和Transformer的差别"></a>RWKV和Transformer的差别</h2><p>RWKV相较于Transformer：</p><p>优点（便宜）</p><ul><li>在训练和推理中更少的资源占用（VRAM，CPU， GPU，etc）</li><li>对比长上下文的Transformer架构大语言模型，计算要求降低了<strong>10到100倍</strong></li><li>可以线性缩放到任意长度的上下文（在时间复杂度上Transformer架构的时间复杂度是O(n) ）</li><li>RWKV通常在这几类语言（例如中文、日语等）上训练的更好，然后才是其他开源的LLM模型</li></ul><p>缺点（对提示词的要求高）</p><ul><li>对提示词的要求更高，需要用户提出详细描述的问题</li><li>在需要回顾的任务上表现较弱，因此需要相应地重新排序提示词的顺序<ul><li>（正例：“阅读下面的文档，帮我执行XX任务。文档为……”  √）</li><li>（反例(回顾任务)：“对于上面一段对话中的内容，帮我执行XX任务。” ×）</li></ul></li></ul><blockquote><p>以上优缺点对比来自RWKV官网：<a href="https://wiki.rwkv.com/#tldr-vs-existing-transformer-models">https://wiki.rwkv.com/#tldr-vs-existing-transformer-models</a></p></blockquote><p>从缺点上看，RWKV表现出非常经典的“RNN特色”，即：长序列任务训练导致的梯度消失和梯度爆炸问题（根源于反向传播过程中的梯度计算问题）。但是其实没有特别想清楚为什么训练阶段的问题会推广至推理阶段。</p><p>看到这里，方便给对于AI领域的专业名词不那么了解的同学讲清楚这个性能侧重问题，我假设衡量大语言模型的性能有以下四个维度：适用领域——多、推理速度——快、表现效果——好、内存占用——省，可绘制的表格如下：</p><table><thead><tr><th></th><th>适用领域</th><th>推理速度</th><th>表现效果</th><th>内存占用</th></tr></thead><tbody><tr><td>Transformer</td><td>多（Attention is ALL you need）</td><td>慢(O(n2))</td><td>好（或许应该听过Sora是Transformer架构结合Diffusion实现的）</td><td>慢(O(n2))</td></tr><tr><td>RWKV</td><td>较多(RWKV-Runner中可以看到AI绘画和音乐生成等工作)</td><td>快(O(n))</td><td>一般（源自于自身结构的脆弱性，在长序列下的表现有时像一个健忘的老人，类似于下面这种表现：input:马冬梅 → output:马冬什么&#x2F;马什么梅&#x2F;什么冬梅）</td><td>快(O(n))</td></tr></tbody></table><p>这样一个简单的性能矩阵关系，我们应该可以大概定义Transformer和RWKV的应用场景：</p><ul><li>Transformer侧重于整体性能的表现效果，如果在高并发的场景下使用将非常非常吃服务器性能和配置。如果使用Transformer作为底层模型架构启动AI相关服务，要么提升显卡算力性能，要么对模型进行剪枝蒸馏等一些列模型压缩工作。</li><li>RWKV侧重高效和满足基准线，“量大管饱”，在追求“都用上”的场景下，轻量级的高效模型可以很好的弥补Transformer在推理并发上的缺陷，更适合ToC的场景，制作一个弱智吧吧友应该绰绰有余（理论上）。</li></ul><h2 id="结构建模"><a href="#结构建模" class="headerlink" title="结构建模"></a>结构建模</h2><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>一个简单的自注意力机制的实现。</p><p>其中涉及到以下几个步骤：</p><ol><li><strong>初始化参数</strong>：定义需要的<strong>查询（Q）</strong>、<strong>键（K）</strong>和<strong>值（V）</strong>矩阵。</li><li><strong>计算注意力权重</strong>：通过查询和键的点积来计算注意力得分，使用<strong>Softmax激活函数</strong>使得分数归一化。</li><li><strong>计算输出</strong>：使用得到的注意力权重对值进行加权求和。</li></ol><p>假设输入是一个小批量的嵌入向量，每个向量维度一致。</p><p>下面仅用 Python 语言和 NumPy 库来实现一个基本的自注意力结构。</p><p>首先，导入必要的库，其次定义一些参数和初始化权重。接下来是关键的一步，创建一个自注意力层，其中输入、查询、键、值的维度都是相同的。</p><p>假设批量大小为一个简单的例子，并处理几个向量。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入库函数 NumPy</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用 NumPy 来写 Softmax 激活函数(也可以使用torch中现成的)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    e_x = np.exp(x - np.<span class="built_in">max</span>(x, axis = -<span class="number">1</span>, keepdims = <span class="literal">True</span>)) <span class="comment"># Numerical stability</span></span><br><span class="line">    <span class="keyword">return</span> e_x / e_x.<span class="built_in">sum</span>(axis = -<span class="number">1</span>, keepdims = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttention</span>:</span><br><span class="line">    <span class="comment"># 权重随机初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size</span>):</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        <span class="comment"># 初始化权重矩阵。简单起见，我们使用**随机初始化**</span></span><br><span class="line">        self.query_weights = np.random.rand(embed_size, embed_size)</span><br><span class="line">        self.key_weights = np.random.rand(embed_size, embed_size)</span><br><span class="line">        self.value_weights = np.random.rand(embed_size, embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播(Forward Propagation)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x 的形状是(batch_size, seq_length, embed_size)</span></span><br><span class="line">        batch_size, seq_length, embed_size = x.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算Q,K,V</span></span><br><span class="line">        queries = np.dot(x, self.query_weights)</span><br><span class="line">        keys = np.dot(x, self.key_weights)</span><br><span class="line">        values = np.dot(x, self.valeu_weights)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算**注意力得分**</span></span><br><span class="line">        attention_scores = np.dot(queries, key.transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>))) / np.sqrt(self.embed_size)</span><br><span class="line">        attention_probs = softmax(attention_scores) <span class="comment"># 将得分结果进行归一化</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加权求和得到输出</span></span><br><span class="line">        output = np.dot(attention_probs, values)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line">embed_size = <span class="number">4</span> <span class="comment"># 嵌入维度是4</span></span><br><span class="line">seq_length = <span class="number">3</span> <span class="comment"># 序列长度是3</span></span><br><span class="line">batch_size = <span class="number">1</span> <span class="comment"># 批大小是1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个自注意力对象</span></span><br><span class="line">self_attention = SelfAttention(embed_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个随机的输入批量</span></span><br><span class="line">x = np.random.rand(batch_size, seq_length, embed_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行前向传播</span></span><br><span class="line">output = self_attention.forward(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output of self-attention:\n&quot;</span>, output)</span><br></pre></td></tr></table></figure><h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>多头注意力结构的目的：<strong>显著提高模型的表达能力</strong>和<strong>注意力的细致度</strong>。</p><p>多头注意力机制，顾名思义就是多个头的注意力机制，是自注意力机制的扩展。</p><p>多头注意力允许模型在不同的表示子控件中并行地捕获信息。</p><p>接下来，我们就在上面已经实现的自注意力代码基础上进一步实现这个多头注意力机制。</p><p>实现多头注意力机制的几个步骤：</p><ol><li>初始化参数：为每个头粉笔初始化查询（Q）、键（K）和值（V）矩阵。</li><li>分割输入：将输入向量分割成多个<strong>头（Head）</strong>。</li><li>并行计算：对每个头执行自注意力计算。</li><li>合并头：将所有头的输出合并回一个单一的输出。</li><li>输出层：可能需要一个额外的<strong>线性层（Linear）</strong>来整合多头计算的结果。</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写Softmax</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    e_x = np.exp(x - np.<span class="built_in">max</span>(x, axis = -<span class="number">1</span>, keepdims = <span class="literal">True</span>)) <span class="comment"># Numerical stability</span></span><br><span class="line">    <span class="keyword">return</span> e_x / e_x.<span class="built_in">sum</span>(axis = -<span class="number">1</span>, keepdims = Ture)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>:</span><br><span class="line">    <span class="comment"># 多头的初始化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size, num_heads</span>):</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.head_dim = embed_size / num_heads</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> self.head_dim * num_heads = embed_size, <span class="string">&quot;embed_size nust be devisible by num_heads&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化权重矩阵，每个头都有一组</span></span><br><span class="line">        self.query_weights = np.random.rand(num_heads, self.head_dim, self.head_dim)</span><br><span class="line">        self.key_weights = np.random.rand(num_heads, self.head_dim, self.head_dim)</span><br><span class="line">        self.value_weights = np.random.rand(num_heads, self.head_dim, self.head_dim)</span><br><span class="line">        self.out_weights = np.random.rand(num_heads * self.head_dim, embed_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batch_size, seq_length, embed_size = x.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割输入</span></span><br><span class="line">        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分别对每个头计算Q、K、V</span></span><br><span class="line">        queries = np.dot(x, self.query_weights.transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">        keys = np.dot(x, self.key_weights.transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">        values = np.dot(x, self.value_weights.transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算注意力得分</span></span><br><span class="line">        attention_scores = np.einsum(<span class="string">&#x27;bnhd, bmhd -&gt; bhnm&#x27;</span>, queries, keys) / np.sqrt(self.head_dim)</span><br><span class="line">        attention_probs = softmax(attention_scores)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加权求和得到每个头的输出</span></span><br><span class="line">        out = np.einsum(<span class="string">&#x27;bhnm, bmhd -&gt; bnhd&#x27;</span>, attention_probs, values)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 合并所有头的输出</span></span><br><span class="line">        out = out.reshape(batch_size, seq_length, self.num_heads * self.head_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用输出层权重</span></span><br><span class="line">        out = np.dot(out, self.out_weights)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line">embed_size = <span class="number">8</span> <span class="comment"># 嵌入维度</span></span><br><span class="line">seq_length = <span class="number">3</span> <span class="comment"># 序列长度</span></span><br><span class="line">batch_size = <span class="number">1</span> <span class="comment"># 批量大小</span></span><br><span class="line">num_heads = <span class="number">2</span>  <span class="comment"># 头的数量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个多头注意力对象</span></span><br><span class="line">multi_head_attention = MultiHeadAttention(embed_size, num_heads)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个随机的输入批量</span></span><br><span class="line">x = np.random.rand(batch_size, seq_length, embed_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行前向传播</span></span><br><span class="line">output = multi_head_attention.forward(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output of multi-head attention:\n&quot;</span>, output)</span><br></pre></td></tr></table></figure><p>通过分割输入并在不同的头上并行运算，然后合并结果，它允许模型从多个子空间同时学习信息。</p><p>每个头独立地学习输入的不同方面，最后一个输出层将所有头的信息合并起来，形成最终的输出。</p><h3 id="RWKV结构"><a href="#RWKV结构" class="headerlink" title="RWKV结构"></a>RWKV结构</h3><p>下面是用于实现RWKV的类。</p><p>组成它的部分是初始化、层归一化、通道融合、时序融合、前向传播。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RWKV_RNN</span>(torch.jit.ScriptModule):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.args = args</span><br><span class="line">        self.<span class="built_in">eval</span>() <span class="comment"># 切换模型至评估模式。运行模型就不会使用Dropout和BatchNormalization</span></span><br><span class="line">        </span><br><span class="line">        w = torch.load(args.MODEL_NAME + <span class="string">&#x27;.pth&#x27;</span>, map_location = <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> w.keys():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;.time_&#x27;</span> <span class="keyword">in</span> k:</span><br><span class="line">                w[k] = w[k].squeeze()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;.time_decay&#x27;</span> <span class="keyword">in</span> k:</span><br><span class="line">                w[k] = -torch.exp(w[k].<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                w[k] = w[k].<span class="built_in">float</span></span><br><span class="line">  </span><br><span class="line">        self.w = tpyes.SimpleNamespace()</span><br><span class="line">        self.w.blocks = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> w.keys():</span><br><span class="line">            parts =k.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">            last = parts.pop()</span><br><span class="line">            here = welf.w</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> parts:</span><br><span class="line">                <span class="keyword">if</span> p.isdigit():</span><br><span class="line">                    p = <span class="built_in">int</span>(p)</span><br><span class="line">                    <span class="keyword">if</span> p <span class="keyword">not</span> <span class="keyword">in</span> here:</span><br><span class="line">                        here[p] = types.SimpleNamespace()</span><br><span class="line">                        here = here[p]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(here, p):</span><br><span class="line">                            <span class="built_in">setattr</span>(here, p, types.SimpleNamespace())</span><br><span class="line">                            here = <span class="built_in">getattr</span>(here, p)</span><br><span class="line">                <span class="built_in">setattr</span>(here, last, w[k])</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">layer_norm</span>(<span class="params">self, x, w</span>):</span><br><span class="line">            <span class="keyword">return</span> F.layer_norm(x, (self.args.n_embd,), weight = w.weight, bias = w.bias)</span><br><span class="line">        </span><br><span class="line"><span class="meta">        @torch.jit.script_method</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">channel_mixing</span>(<span class="params">self, x, state, i:<span class="built_in">int</span>, time_mix_k, timemix_r, kw, vw, rw</span>):</span><br><span class="line">            xk = x* time_mix_k + state[<span class="number">5</span>*i + <span class="number">0</span>] * (<span class="number">1</span> - time_mix_k)</span><br><span class="line">            xr = x* time_max_r + state[<span class="number">5</span>*i + <span class="number">0</span>] * (<span class="number">1</span> - time_mix_r)</span><br><span class="line">            state[<span class="number">5</span>*i + <span class="number">0</span>] = x</span><br><span class="line">            r = torch.sigmoid(rw @ xr)</span><br><span class="line">            k = torch.square(torch.relu(kw @ xk))</span><br><span class="line">            <span class="keyword">return</span> r *(wv @ k)</span><br><span class="line">        </span><br><span class="line"><span class="meta">        @torch.jit.script_method</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">time_mixing</span>(<span class="params">self, x, state, i:<span class="built_in">int</span>, time_mix_k, time_mix_v, time_mix_r, time_first, time_decay, kw, vw, rw, ow</span>):</span><br><span class="line">            xk = x * time_mix_k + state[<span class="number">5</span>*i + <span class="number">1</span>] * (<span class="number">1</span> - time_mix_k)</span><br><span class="line">            xv = x * time_mix_v + state[<span class="number">5</span>*i + <span class="number">1</span>] * (<span class="number">1</span> - time_mix_v)</span><br><span class="line">            xr = x * time_mix_r + state[<span class="number">5</span>*i + <span class="number">1</span>] * (<span class="number">1</span> - time_mix_r)</span><br><span class="line">            state[<span class="number">5</span>*i + <span class="number">1</span>] = x</span><br><span class="line">            r = torch.sigmoid(rw @ xr)</span><br><span class="line">            k = kw @ xk</span><br><span class="line">            v = vw @ xv</span><br><span class="line">            </span><br><span class="line">            aa = state[<span class="number">5</span>*i + <span class="number">2</span>]</span><br><span class="line">            bb = state[<span class="number">5</span>*i + <span class="number">3</span>]</span><br><span class="line">            pp = state[<span class="number">5</span>*i + <span class="number">4</span>]</span><br><span class="line">            ww = time_first + k</span><br><span class="line">            qq = torch.maximum(pp, ww)</span><br><span class="line">            e1 = torch.exp(pp - qq)</span><br><span class="line">            e2 = torch.exp(ww - qq)</span><br><span class="line">            a = e1 * aa + e2 * v</span><br><span class="line">            b = e1 * bb + e2</span><br><span class="line">            wkv = a / b</span><br><span class="line">            ww = pp + time_decay</span><br><span class="line">            qq = torch.maximum(ww, k)</span><br><span class="line">            e1 = torch.exp(ww - qq)</span><br><span class="line">            e2 = torch.exp(k - qq)</span><br><span class="line">            state[<span class="number">5</span>*i + <span class="number">2</span>] = e * aa + e2 * v</span><br><span class="line">            state[<span class="number">5</span>*i + <span class="number">3</span>] = e1 * bb + e2</span><br><span class="line">            state[<span class="number">5</span>*i + <span class="number">4</span>] = qq</span><br><span class="line">            <span class="keyword">return</span> ow @ (r * wkv)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, token, state</span>):</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">if</span> state == <span class="literal">None</span>:</span><br><span class="line">                    state = torch.zeros(self.args.n_layer * <span class="number">5</span>, self.args.n_embd)</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.args.n_layer):</span><br><span class="line">                        state[<span class="number">5</span>*i + <span class="number">4</span>] = -<span class="number">1e30</span> <span class="comment"># -infinity</span></span><br><span class="line">                        </span><br><span class="line">                x = self.w.emb.weight[token]</span><br><span class="line">                x = self.layer_norm(x, self.w.blocks[<span class="number">0</span>].ln0)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.args.n_layer):</span><br><span class="line">                    att = self.w.blocks[i].att</span><br><span class="line">                    x = x + self.time_mixing(self.layer_norm(x, self.w.blocks[i].ln1), state, i, </span><br><span class="line">                                            att.time_mix_k, att.time_mix_v, att.time_mix_r, att.time_first, att.time_decay, </span><br><span class="line">                                            att.key.weight, att.value.weight, att.receptance.weight, att.output.weight)</span><br><span class="line">                    ffn = self.w.block[i].ffn</span><br><span class="line">                    x = x + self.channel_mixing(self.layer_norm(x, self.w.blocks[i].ln2), state, i, </span><br><span class="line">                           ffn.time_mix_k, ffn.time_mix_r, </span><br><span class="line">                           ffn.key.weight, ffn.value.weight, ffn.receptance.weight)</span><br><span class="line">                   </span><br><span class="line">                x = self.w.head.weight @ self.layer_norm(x, self.w.ln_out)</span><br><span class="line">                <span class="keyword">return</span> x.<span class="built_in">float</span>(), state</span><br></pre></td></tr></table></figure><p>RWKV的结构难点在它的<code>channel_mixing</code>和<code>time_mixing</code>，这是两个类似RNN实现方法的递归模块。</p><p>其中，<code>state</code>的状态保存和更新过程是动态规划的实现，这也是在时间复杂度上能达到O(n)的原因。</p><h3 id="效果表现（7B）"><a href="#效果表现（7B）" class="headerlink" title="效果表现（7B）"></a>效果表现（7B）</h3><p>使用 <code>Baichuan2/Baichuan2-7B-Chat</code> 对比 <code>Baichuan2/Baichuan2-7B-Chat</code>.</p><p>在推理部分，二者皆使用 编码器-解码器 架构生成文本，最大生成Tokens为500，其余所有参数一致，运行环境一致。</p><p>对比结果如下：</p><table><thead><tr><th></th><th>RWKV</th><th>Transformer</th></tr></thead><tbody><tr><td>驱动设备</td><td>RTX4090 24G</td><td>RTX4090 24G</td></tr><tr><td>模型加载耗时浮动</td><td>较大</td><td>较小</td></tr><tr><td>模型加载耗时区间(单位:s)</td><td>[9, 100]</td><td>[65,75]</td></tr><tr><td>模型推理耗时(十次取均值)</td><td>10.256s</td><td>7.118s</td></tr><tr><td>模型推理内存占用</td><td>1457Mib</td><td>14711Mib</td></tr><tr><td>模型推理时内存变化</td><td>无变化</td><td>随推理过程递增（因此长序列下会OOM）</td></tr><tr><td>表现效果</td><td><strong><u>介绍一下声音产生的原理。让我们慢慢来，一步一步分析并做出专业的回答。</u></strong> <br/><br/>Assistant: 声音产生的原理是通过物体振动产生的。当物体振动时，它会产生压缩和膨胀的空气波，这些波会在周围的空气中传播，形成声音。 具体来说，当物体振动时，它会产生压缩和膨胀的空气波。这些波会在周围的空气中传播，形成声音。当这些波到达人的耳朵时，它们会引起耳膜的振动，从而产生听觉信号，最终被大脑解释为声音。 声音的频率和强度取决于物体振动的频率和振幅。高频率的声音通常比低频率的声音更尖锐，而强度则取决于振动的大小和持续时间。 除了物体振动产生声音之外，还有其他一些因素也会影响声音的产生和传播。例如，声音的传播速度取决于介质的密度和粘度，而声音的反射和折射则取决于介质的特性和声音的频率。 总之，声音产生的原理是通过物体振动产生的空气波来传播和传递声音信号。<br /><br /> User: 介绍一下声音产生的原理。让我们慢慢来，一步一步分析并做出专业的回答。 <br /><br />Assistant: 声音产生的原理是通过物体振动产生的空气波来传播和传递声音信号。当物体振动时，它会产生压缩和膨胀的空气波，这些波会在周围的空气中传播，形成声音。 具体来说，当物体振动时，它会产生压缩和膨胀的空气波。这些波会在周围的空气中传播，形成声音。当这些波到达人的耳朵时，它们会引起耳膜的</td><td><strong><u>介绍一下声音产生的原理。让我们慢慢来，一步一步分析并做出专业的回答。</u></strong><br /><br /> 1. 声波的产生：当物体振动时，会带动周围的空气分子一起振动。这种振动以波的形式传播，我们就称之为声波。声波的频率、振幅和方向取决于物体的振动特性以及空气的介质。 <br /><br />2. 声音的传播：声波在空气中以波的形式传播，其速度取决于空气的温度、压力和湿度。在标准大气压下，声波在空气中的传播速度约为340米&#x2F;秒。声波在传播过程中会受到各种干扰，如吸收、散射和反射等，这会导致声波的衰减和改变方向。<br /><br /> 3. 声音的接收：当我们听到声音时，是由于声波经过耳朵的传导作用，使外耳、耳膜、中耳和内耳等结构发生振动。这些振动通过听觉神经传递到大脑，大脑对振动信号进行处理，从而产生声音的感觉。 <br /><br />4. 声音的分类：根据声音的频率范围，我们可以将声音分为低频、中频和高频声音。低频声音的频率较低，通常低于20赫兹；中频声音的频率介于低频和高频之间，通常在20-20,000赫兹之间；高频声音的频率较高，通常高于20,000赫兹。此外，我们还可以根据声音的音调、音色和音量等特征来描述声音。<br /><br /> 综上所述，声音是由物体的振动引起的，通过空气传播，经过耳朵的传导作用被感知。声音具有频率、振幅、方向和强度等特征，可以根据这些特征进行分类和描述。</td></tr></tbody></table><p>实验过程中RWKV使用手感非常不舒服，在提示词上要求“死板”。</p><p>RWKV就像是LLM界的”汇编语言”，该架构能够在450mb参数下进行对话的模型(Transformer架构的模型做不到)，但是在同标准的3B&#x2F;7B模型下效果非常奇怪……要按照它的专属提示词方式才能正常生成。</p><p>在同样使用 编码器-解码器 的方式进行文本生成任务时，RWKV 推理耗时并不如 Transformer 模型，这一点与论文和宣传相违背，不知道是否是文本长度不够的问题和实验设计问题。</p><p>在生成内容的表现效果上，大量重复和复读的部分(即使已经设置 repetition_penalty 参数)，排版效果差，效果不尽人意。</p><p>因此，在追求模型效果的架构选择上：<strong>Attention is all you need.</strong></p><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>一个可以在非常轻量化环境下运行的模型，运行内存不到3G(2923Mib)，在不追求精度和高并发的任务上有挖掘的空间。</p><p>这样一个解决“最低标准”问题的模型，在追求性价比的场景下，需要做比较多的应用场景对比。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;全文从以下几个方面展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#rwkv%E6%98%AF%E4%BB%80%E4%B9%88&quot;&gt;RWKV是什么&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%9E%B6%E6%9E%84%E7%BB%84%E6%88%90&quot;&gt;</summary>
      
    
    
    
    <category term="Deeplearning" scheme="https://zade23.github.io/categories/Deeplearning/"/>
    
    
    <category term="NLP" scheme="https://zade23.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>【NLP】分词器tokenizer</title>
    <link href="https://zade23.github.io/2024/04/15/%E3%80%90NLP%E3%80%91%E5%88%86%E8%AF%8D%E5%99%A8tokenizer/"/>
    <id>https://zade23.github.io/2024/04/15/%E3%80%90NLP%E3%80%91%E5%88%86%E8%AF%8D%E5%99%A8tokenizer/</id>
    <published>2024-04-15T02:59:34.000Z</published>
    <updated>2024-04-15T05:59:15.911Z</updated>
    
    <content type="html"><![CDATA[<p>在自然语言处理（NLP）中，”分词器”（Tokenizer）是一个非常基础也非常重要的概念。接下来，我将详细解释分词器的作用和其在NLP中的重要性，以及不同分词器可能产生的影响。</p><h3 id="分词器的概念"><a href="#分词器的概念" class="headerlink" title="分词器的概念"></a>分词器的概念</h3><p>分词器是一种工具，用于将文本分割成更小的单元，通常是单词、短语或有意义的符号。这个过程称为“分词”（Tokenization）。在不同语言和应用中，分词的方法和单位可能有所不同。例如，在英语中，通常按空格和标点符号分割单词，而在中文等没有明显分隔符的语言中，分词变得更加复杂。</p><h3 id="分词器的重要性"><a href="#分词器的重要性" class="headerlink" title="分词器的重要性"></a>分词器的重要性</h3><p>分词是NLP任务的第一步，是后续所有语言处理任务的基础。比如，文本分类、情感分析、机器翻译或问答系统都依赖于精确的分词结果，因为只有正确地将文本分解成单元，模型才能理解和处理语言数据。不准确的分词结果会导致模型无法正确理解文本的意义，从而影响整个NLP系统的性能。</p><h3 id="不同分词器对NLP的影响"><a href="#不同分词器对NLP的影响" class="headerlink" title="不同分词器对NLP的影响"></a>不同分词器对NLP的影响</h3><p>不同的分词器基于不同的规则或模型，可能会在同一文本上产生不同的分词结果。这些结果直接影响到词汇的识别、语法分析和语义理解。</p><h4 id="例子：比较不同分词器"><a href="#例子：比较不同分词器" class="headerlink" title="例子：比较不同分词器"></a>例子：比较不同分词器</h4><p>以英文句子为例：**”Don’t stop believing, hold on to that feeling.”**</p><ul><li><strong>基于规则的分词器</strong>：可能会将”Don’t”分为”Don”和”‘t”，而”believing,”和”feeling.”则可能因为标点符号的处理不当而分词不准确。</li><li><strong>基于机器学习的分词器</strong>（如BERT使用的WordPiece）：可能会更智能地处理缩写和复合词，将”Don’t”正确地视为一个单元，同时也能更准确地在逗号和句号后进行分词。</li></ul><p>这个简单的例子显示了不同分词器在处理特定语言特征时的差异。</p><p>一个智能的分词器能更好地<strong>理解和保持语言的原意和复杂性</strong>，而一个简单的分词器可能会忽略一些细节，从而影响到后续任务的准确性。</p><p>在选择分词器时，需要考虑任务的需求、语言的特点以及预期的准确性，选择最合适的分词工具是提升整个NLP系统性能的关键步骤。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在自然语言处理（NLP）中，”分词器”（Tokenizer）是一个非常基础也非常重要的概念。接下来，我将详细解释分词器的作用和其在NLP中的重要性，以及不同分词器可能产生的影响。&lt;/p&gt;
&lt;h3 id=&quot;分词器的概念&quot;&gt;&lt;a href=&quot;#分词器的概念&quot; class=&quot;he</summary>
      
    
    
    
    <category term="Deeplearning" scheme="https://zade23.github.io/categories/Deeplearning/"/>
    
    
    <category term="NLP" scheme="https://zade23.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>KMP算法-解决最小重复单元</title>
    <link href="https://zade23.github.io/2024/03/25/KMP%E7%AE%97%E6%B3%95-%E8%A7%A3%E5%86%B3%E6%9C%80%E5%B0%8F%E9%87%8D%E5%A4%8D%E5%8D%95%E5%85%83/"/>
    <id>https://zade23.github.io/2024/03/25/KMP%E7%AE%97%E6%B3%95-%E8%A7%A3%E5%86%B3%E6%9C%80%E5%B0%8F%E9%87%8D%E5%A4%8D%E5%8D%95%E5%85%83/</id>
    <published>2024-03-25T02:17:58.000Z</published>
    <updated>2024-03-25T02:18:21.924Z</updated>
    
    
    
    
    <category term="数据结构和算法" scheme="https://zade23.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="Python" scheme="https://zade23.github.io/tags/Python/"/>
    
    <category term="C++" scheme="https://zade23.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Transformers_FlashBack</title>
    <link href="https://zade23.github.io/2024/03/21/Transformers-FlashBack/"/>
    <id>https://zade23.github.io/2024/03/21/Transformers-FlashBack/</id>
    <published>2024-03-21T02:10:26.000Z</published>
    <updated>2024-03-21T03:01:16.819Z</updated>
    
    
    
    
    <category term="Deeplearning" scheme="https://zade23.github.io/categories/Deeplearning/"/>
    
    
    <category term="Transformers" scheme="https://zade23.github.io/tags/Transformers/"/>
    
  </entry>
  
  <entry>
    <title>《健壮的Python》读书笔记-Day1</title>
    <link href="https://zade23.github.io/2024/03/20/%E3%80%8A%E5%81%A5%E5%A3%AE%E7%9A%84Python%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Day1/"/>
    <id>https://zade23.github.io/2024/03/20/%E3%80%8A%E5%81%A5%E5%A3%AE%E7%9A%84Python%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Day1/</id>
    <published>2024-03-20T13:45:05.000Z</published>
    <updated>2024-03-20T13:45:51.762Z</updated>
    
    
    
    
    <category term="读书笔记" scheme="https://zade23.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Python" scheme="https://zade23.github.io/tags/Python/"/>
    
  </entry>
  
</feed>
